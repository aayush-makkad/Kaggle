{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "train_raw = pd.read_csv('../titanic/train.csv')\n",
    "#Exploration of data\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corrmat = train_raw.corr()\n",
    "top_corr_features = corrmat.index\n",
    "plt.figure(figsize=(20,20))\n",
    "#plot heat map\n",
    "g=sns.heatmap(train_raw[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performing same data transformations\n",
    "from sklearn import preprocessing\n",
    "#train_raw.drop(columns=['PassengerId'],inplace=True)\n",
    "train_raw['Cabin'] = train_raw['Cabin'].fillna(0)\n",
    "train_raw['Cabin'] = train_raw['Cabin'].where(train_raw['Cabin']==0,1)\n",
    "train_raw.drop(columns=['Name','Ticket'],inplace=True)\n",
    "train_raw = pd.concat([train_raw,pd.get_dummies(train_raw['Sex'],prefix='Sex')],axis = 1)\n",
    "train_raw.drop(columns='Sex',inplace=True)\n",
    "train_raw = pd.concat([train_raw,pd.get_dummies(train_raw['Embarked'],prefix='Embarked')],axis = 1)\n",
    "train_raw.drop(columns=['Embarked'],inplace=True)\n",
    "train_raw['Fare'] = train_raw['Fare'].fillna(train_raw['Fare'].median())\n",
    "fare_col = train_raw.Fare.values\n",
    "fare_col = fare_col.reshape(-1, 1)\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "fare_col_scaled = min_max_scaler.fit_transform(fare_col)\n",
    "train_raw['fare_col_scaled_col'] = fare_col_scaled\n",
    "train_raw.drop(columns=['Fare'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>fare_col_scaled_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.014151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.139136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.103644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass   Age  SibSp  Parch Cabin  Sex_female  \\\n",
       "0            1         0       3  22.0      1      0     0           0   \n",
       "1            2         1       1  38.0      1      0     1           1   \n",
       "2            3         1       3  26.0      0      0     0           1   \n",
       "3            4         1       1  35.0      1      0     1           1   \n",
       "4            5         0       3  35.0      0      0     0           0   \n",
       "\n",
       "   Sex_male  Embarked_C  Embarked_Q  Embarked_S  fare_col_scaled_col  \n",
       "0         1           0           0           1             0.014151  \n",
       "1         0           1           0           0             0.139136  \n",
       "2         0           0           0           1             0.015469  \n",
       "3         0           0           0           1             0.103644  \n",
       "4         1           0           0           1             0.015713  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_df = train_raw[train_raw['Age'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>fare_col_scaled_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.025374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>860</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>864</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.135753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>869</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.018543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>879</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.045771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>177 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  Age  SibSp  Parch Cabin  Sex_female  \\\n",
       "5              6         0       3  NaN      0      0     0           0   \n",
       "17            18         1       2  NaN      0      0     0           0   \n",
       "19            20         1       3  NaN      0      0     0           1   \n",
       "26            27         0       3  NaN      0      0     0           0   \n",
       "28            29         1       3  NaN      0      0     0           1   \n",
       "..           ...       ...     ...  ...    ...    ...   ...         ...   \n",
       "859          860         0       3  NaN      0      0     0           0   \n",
       "863          864         0       3  NaN      8      2     0           1   \n",
       "868          869         0       3  NaN      0      0     0           0   \n",
       "878          879         0       3  NaN      0      0     0           0   \n",
       "888          889         0       3  NaN      1      2     0           1   \n",
       "\n",
       "     Sex_male  Embarked_C  Embarked_Q  Embarked_S  fare_col_scaled_col  \n",
       "5           1           0           1           0             0.016510  \n",
       "17          1           0           0           1             0.025374  \n",
       "19          0           1           0           0             0.014102  \n",
       "26          1           1           0           0             0.014102  \n",
       "28          0           0           1           0             0.015379  \n",
       "..        ...         ...         ...         ...                  ...  \n",
       "859         1           1           0           0             0.014110  \n",
       "863         0           0           0           1             0.135753  \n",
       "868         1           0           0           1             0.018543  \n",
       "878         1           0           0           1             0.015412  \n",
       "888         0           0           0           1             0.045771  \n",
       "\n",
       "[177 rows x 13 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_df[nan_df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_nan_df = train_raw[train_raw['Age'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>fare_col_scaled_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [PassengerId, Survived, Pclass, Age, SibSp, Parch, Cabin, Sex_female, Sex_male, Embarked_C, Embarked_Q, Embarked_S, fare_col_scaled_col]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_nan_df[non_nan_df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>fare_col_scaled_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.025374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PassengerId  Survived  Pclass  Age  SibSp  Parch Cabin  Sex_female  \\\n",
       "5             6         0       3  NaN      0      0     0           0   \n",
       "17           18         1       2  NaN      0      0     0           0   \n",
       "19           20         1       3  NaN      0      0     0           1   \n",
       "26           27         0       3  NaN      0      0     0           0   \n",
       "28           29         1       3  NaN      0      0     0           1   \n",
       "\n",
       "    Sex_male  Embarked_C  Embarked_Q  Embarked_S  fare_col_scaled_col  \n",
       "5          1           0           1           0             0.016510  \n",
       "17         1           0           0           1             0.025374  \n",
       "19         0           1           0           0             0.014102  \n",
       "26         1           1           0           0             0.014102  \n",
       "28         0           0           1           0             0.015379  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# use Ann to predict ages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.callbacks.callbacks import ReduceLROnPlateau\n",
    "def build_neural_net(optimizer,initializer,layer_1_activation,layer_2_activation):\n",
    "    classifier= Sequential()\n",
    "    classifier.add(Dense(units=8,kernel_initializer = initializer,activation=layer_1_activation,input_dim=11))\n",
    "    classifier.add(Dropout(rate=0.2))\n",
    "    classifier.add(Dense(units=4,kernel_initializer = initializer,activation=layer_2_activation))\n",
    "    #classifier.add(Dropout(rate=0.2))\n",
    "    classifier.add(Dense(units=1,kernel_initializer = initializer,activation='sigmoid'))\n",
    "    classifier.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = build_neural_net('adam','uniform','relu','relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build data to be fed to ANN\n",
    "x_col = [col for col in non_nan_df.columns if col!= 'Age']\n",
    "y_col = ['Age']\n",
    "x_col = [items for items in x_col if items!='PassengerId']\n",
    "x_col = [items for items in x_col if items!='Survived']\n",
    "#x_col = [items for items in x_col if items!='SibSp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_imputation_x = non_nan_df[x_col]\n",
    "training_imputation_y = non_nan_df[y_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>fare_col_scaled_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.014151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.139136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.103644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  SibSp  Parch Cabin  Sex_female  Sex_male  Embarked_C  Embarked_Q  \\\n",
       "0       3      1      0     0           0         1           0           0   \n",
       "1       1      1      0     1           1         0           1           0   \n",
       "2       3      0      0     0           1         0           0           0   \n",
       "3       1      1      0     1           1         0           0           0   \n",
       "4       3      0      0     0           0         1           0           0   \n",
       "\n",
       "   Embarked_S  fare_col_scaled_col  \n",
       "0           1             0.014151  \n",
       "1           0             0.139136  \n",
       "2           1             0.015469  \n",
       "3           1             0.103644  \n",
       "4           1             0.015713  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_imputation_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age\n",
       "0  22.0\n",
       "1  38.0\n",
       "2  26.0\n",
       "3  35.0\n",
       "4  35.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_imputation_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Age]\n",
       "Index: []"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_imputation_y[training_imputation_y.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fir the regression model\n",
    "model = Lasso(alpha=0.1)\n",
    "model_fit = model.fit(training_imputation_x,training_imputation_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>fare_col_scaled_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.025374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PassengerId  Survived  Pclass  Age  SibSp  Parch Cabin  Sex_female  \\\n",
       "5             6         0       3  NaN      0      0     0           0   \n",
       "17           18         1       2  NaN      0      0     0           0   \n",
       "19           20         1       3  NaN      0      0     0           1   \n",
       "26           27         0       3  NaN      0      0     0           0   \n",
       "28           29         1       3  NaN      0      0     0           1   \n",
       "\n",
       "    Sex_male  Embarked_C  Embarked_Q  Embarked_S  fare_col_scaled_col  \n",
       "5          1           0           1           0             0.016510  \n",
       "17         1           0           0           1             0.025374  \n",
       "19         0           1           0           0             0.014102  \n",
       "26         1           1           0           0             0.014102  \n",
       "28         0           0           1           0             0.015379  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_laso = nan_df[x_col]\n",
    "y_predictions_lasso = model.predict(x_test_laso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amakkad\\AppData\\Local\\Continuum\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "y_predictions_lasso\n",
    "nan_df['predicted_age'] = y_predictions_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amakkad\\AppData\\Local\\Continuum\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\pandas\\core\\frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "nan_df.head(10)\n",
    "nan_df.drop(columns=['Age'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amakkad\\AppData\\Local\\Continuum\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "nan_df['Age'] = y_predictions_lasso\n",
    "nan_df.drop(columns=['predicted_age'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>fare_col_scaled_col</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016510</td>\n",
       "      <td>28.620065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.025374</td>\n",
       "      <td>34.967788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014102</td>\n",
       "      <td>23.831941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014102</td>\n",
       "      <td>26.619761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015379</td>\n",
       "      <td>25.832245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015412</td>\n",
       "      <td>28.529624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.285990</td>\n",
       "      <td>32.835182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015127</td>\n",
       "      <td>25.832245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014110</td>\n",
       "      <td>26.619761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015412</td>\n",
       "      <td>26.619761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PassengerId  Survived  Pclass  SibSp  Parch Cabin  Sex_female  Sex_male  \\\n",
       "5             6         0       3      0      0     0           0         1   \n",
       "17           18         1       2      0      0     0           0         1   \n",
       "19           20         1       3      0      0     0           1         0   \n",
       "26           27         0       3      0      0     0           0         1   \n",
       "28           29         1       3      0      0     0           1         0   \n",
       "29           30         0       3      0      0     0           0         1   \n",
       "31           32         1       1      1      0     1           1         0   \n",
       "32           33         1       3      0      0     0           1         0   \n",
       "36           37         1       3      0      0     0           0         1   \n",
       "42           43         0       3      0      0     0           0         1   \n",
       "\n",
       "    Embarked_C  Embarked_Q  Embarked_S  fare_col_scaled_col        Age  \n",
       "5            0           1           0             0.016510  28.620065  \n",
       "17           0           0           1             0.025374  34.967788  \n",
       "19           1           0           0             0.014102  23.831941  \n",
       "26           1           0           0             0.014102  26.619761  \n",
       "28           0           1           0             0.015379  25.832245  \n",
       "29           0           0           1             0.015412  28.529624  \n",
       "31           1           0           0             0.285990  32.835182  \n",
       "32           0           1           0             0.015127  25.832245  \n",
       "36           1           0           0             0.014110  26.619761  \n",
       "42           1           0           0             0.015412  26.619761  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = pd.concat([nan_df,non_nan_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>fare_col_scaled_col</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016510</td>\n",
       "      <td>28.620065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.025374</td>\n",
       "      <td>34.967788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014102</td>\n",
       "      <td>23.831941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014102</td>\n",
       "      <td>26.619761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015379</td>\n",
       "      <td>25.832245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015412</td>\n",
       "      <td>28.529624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.285990</td>\n",
       "      <td>32.835182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015127</td>\n",
       "      <td>25.832245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014110</td>\n",
       "      <td>26.619761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015412</td>\n",
       "      <td>26.619761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PassengerId  Survived  Pclass  SibSp  Parch Cabin  Sex_female  Sex_male  \\\n",
       "5             6         0       3      0      0     0           0         1   \n",
       "17           18         1       2      0      0     0           0         1   \n",
       "19           20         1       3      0      0     0           1         0   \n",
       "26           27         0       3      0      0     0           0         1   \n",
       "28           29         1       3      0      0     0           1         0   \n",
       "29           30         0       3      0      0     0           0         1   \n",
       "31           32         1       1      1      0     1           1         0   \n",
       "32           33         1       3      0      0     0           1         0   \n",
       "36           37         1       3      0      0     0           0         1   \n",
       "42           43         0       3      0      0     0           0         1   \n",
       "\n",
       "    Embarked_C  Embarked_Q  Embarked_S  fare_col_scaled_col        Age  \n",
       "5            0           1           0             0.016510  28.620065  \n",
       "17           0           0           1             0.025374  34.967788  \n",
       "19           1           0           0             0.014102  23.831941  \n",
       "26           1           0           0             0.014102  26.619761  \n",
       "28           0           1           0             0.015379  25.832245  \n",
       "29           0           0           1             0.015412  28.529624  \n",
       "31           1           0           0             0.285990  32.835182  \n",
       "32           0           1           0             0.015127  25.832245  \n",
       "36           1           0           0             0.014110  26.619761  \n",
       "42           1           0           0             0.015412  26.619761  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>fare_col_scaled_col</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [PassengerId, Survived, Pclass, SibSp, Parch, Cabin, Sex_female, Sex_male, Embarked_C, Embarked_Q, Embarked_S, fare_col_scaled_col, Age]\n",
       "Index: []"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data[final_data.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_col = final_data.Age.values\n",
    "age_col = age_col.reshape(-1, 1)\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "age_col_scaled = min_max_scaler.fit_transform(age_col)\n",
    "final_data['age_col_scaled_col'] = age_col_scaled\n",
    "final_data.drop(columns=['Age'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_col_x = [ col for col in final_data.columns if col!='Survived']\n",
    "train_col_x = [ col for col in train_col_x if col!='PassengerId']\n",
    "#train_col_x = [items for items in train_col_x if items!='SibSp']\n",
    "train_col_y = ['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_data[train_col_x]\n",
    "Y = final_data[train_col_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = RandomForestClassifier(max_depth=12, random_state=0,n_estimators=140)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Ann to predict ages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.callbacks.callbacks import ReduceLROnPlateau\n",
    "def build_neural_net_2(optimizer,initializer,layer_1_activation,layer_2_activation):\n",
    "    classifier= Sequential()\n",
    "    classifier.add(Dense(units=8,kernel_initializer = initializer,activation=layer_1_activation,input_dim=11))\n",
    "    classifier.add(Dropout(rate=0.2))\n",
    "    classifier.add(Dense(units=4,kernel_initializer = initializer,activation=layer_2_activation))\n",
    "    #classifier.add(Dropout(rate=0.2))\n",
    "    classifier.add(Dense(units=1,kernel_initializer = initializer,activation='sigmoid'))\n",
    "    classifier.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amakkad\\AppData\\Local\\Continuum\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "model_fit3= model3.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8435754189944135"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[110,  12],\n",
       "       [ 16,  41]], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(Y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>fare_col_scaled_col</th>\n",
       "      <th>age_col_scaled_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.030937</td>\n",
       "      <td>0.402845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024106</td>\n",
       "      <td>0.735874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.221098</td>\n",
       "      <td>0.345427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015127</td>\n",
       "      <td>0.409966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>0.529167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.718648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>0.333943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.028302</td>\n",
       "      <td>0.621037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.071731</td>\n",
       "      <td>0.299492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.162932</td>\n",
       "      <td>0.598069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>712 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  SibSp  Parch Cabin  Sex_female  Sex_male  Embarked_C  Embarked_Q  \\\n",
       "403       3      1      0     0           0         1           0           0   \n",
       "626       2      0      0     0           0         1           0           1   \n",
       "393       1      1      0     1           1         0           1           0   \n",
       "428       3      0      0     0           0         1           0           1   \n",
       "400       3      0      0     0           0         1           0           0   \n",
       "..      ...    ...    ...   ...         ...       ...         ...         ...   \n",
       "152       3      0      0     0           0         1           0           0   \n",
       "376       3      0      0     0           1         0           0           0   \n",
       "132       3      1      0     0           1         0           0           0   \n",
       "145       2      1      1     0           0         1           0           0   \n",
       "62        1      1      0     1           0         1           0           0   \n",
       "\n",
       "     Embarked_S  fare_col_scaled_col  age_col_scaled_col  \n",
       "403           1             0.030937            0.402845  \n",
       "626           0             0.024106            0.735874  \n",
       "393           0             0.221098            0.345427  \n",
       "428           0             0.015127            0.409966  \n",
       "400           1             0.015469            0.529167  \n",
       "..          ...                  ...                 ...  \n",
       "152           1             0.015713            0.718648  \n",
       "376           1             0.014151            0.333943  \n",
       "132           1             0.028302            0.621037  \n",
       "145           1             0.071731            0.299492  \n",
       "62            1             0.162932            0.598069  \n",
       "\n",
       "[712 rows x 11 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "712/712 [==============================] - 0s 278us/step - loss: 0.6894 - accuracy: 0.5969\n",
      "Epoch 2/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.6682 - accuracy: 0.5997\n",
      "Epoch 3/1000\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.6216 - accuracy: 0.6208\n",
      "Epoch 4/1000\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.5706 - accuracy: 0.7360\n",
      "Epoch 5/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.5215 - accuracy: 0.7865\n",
      "Epoch 6/1000\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.5104 - accuracy: 0.7809\n",
      "Epoch 7/1000\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.5098 - accuracy: 0.7711\n",
      "Epoch 8/1000\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.5021 - accuracy: 0.7823\n",
      "Epoch 9/1000\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.5096 - accuracy: 0.7809\n",
      "Epoch 10/1000\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.4964 - accuracy: 0.7739\n",
      "Epoch 11/1000\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.4972 - accuracy: 0.7753\n",
      "Epoch 12/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4846 - accuracy: 0.7865\n",
      "Epoch 13/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4962 - accuracy: 0.7851\n",
      "Epoch 14/1000\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4939 - accuracy: 0.7823\n",
      "Epoch 15/1000\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4893 - accuracy: 0.7837\n",
      "Epoch 16/1000\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4965 - accuracy: 0.7795\n",
      "Epoch 17/1000\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4859 - accuracy: 0.7781\n",
      "Epoch 18/1000\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4839 - accuracy: 0.7753\n",
      "Epoch 19/1000\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4910 - accuracy: 0.7753\n",
      "Epoch 20/1000\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4778 - accuracy: 0.7879\n",
      "Epoch 21/1000\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4803 - accuracy: 0.7795\n",
      "Epoch 22/1000\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4705 - accuracy: 0.7935\n",
      "Epoch 23/1000\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4776 - accuracy: 0.7837\n",
      "Epoch 24/1000\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4792 - accuracy: 0.7781\n",
      "Epoch 25/1000\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.4862 - accuracy: 0.7949\n",
      "Epoch 26/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4710 - accuracy: 0.7935\n",
      "Epoch 27/1000\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4830 - accuracy: 0.7978\n",
      "Epoch 28/1000\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4660 - accuracy: 0.7992\n",
      "Epoch 29/1000\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4731 - accuracy: 0.7823\n",
      "Epoch 30/1000\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4669 - accuracy: 0.7978\n",
      "Epoch 31/1000\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.4794 - accuracy: 0.7865\n",
      "Epoch 32/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4720 - accuracy: 0.7978\n",
      "Epoch 33/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4676 - accuracy: 0.7893\n",
      "Epoch 34/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4770 - accuracy: 0.7978\n",
      "Epoch 35/1000\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4703 - accuracy: 0.7893\n",
      "Epoch 36/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4590 - accuracy: 0.7893\n",
      "Epoch 37/1000\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4669 - accuracy: 0.7907\n",
      "Epoch 38/1000\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4663 - accuracy: 0.8006\n",
      "Epoch 39/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4684 - accuracy: 0.7949\n",
      "Epoch 40/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4662 - accuracy: 0.7992\n",
      "Epoch 41/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4658 - accuracy: 0.7949\n",
      "Epoch 42/1000\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.4530 - accuracy: 0.8132\n",
      "Epoch 43/1000\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4617 - accuracy: 0.8020\n",
      "Epoch 44/1000\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4607 - accuracy: 0.7865\n",
      "Epoch 45/1000\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4608 - accuracy: 0.8048\n",
      "Epoch 46/1000\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.4689 - accuracy: 0.7921\n",
      "Epoch 47/1000\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4574 - accuracy: 0.8118\n",
      "Epoch 48/1000\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4650 - accuracy: 0.7935\n",
      "Epoch 49/1000\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4576 - accuracy: 0.8034\n",
      "Epoch 50/1000\n",
      "712/712 [==============================] - 0s 105us/step - loss: 0.4667 - accuracy: 0.8006\n",
      "Epoch 51/1000\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.4622 - accuracy: 0.7949\n",
      "Epoch 52/1000\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.4513 - accuracy: 0.7949\n",
      "Epoch 53/1000\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.4524 - accuracy: 0.8062\n",
      "Epoch 54/1000\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.4576 - accuracy: 0.8062\n",
      "Epoch 55/1000\n",
      "712/712 [==============================] - 0s 105us/step - loss: 0.4638 - accuracy: 0.8020\n",
      "Epoch 56/1000\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.4664 - accuracy: 0.7935\n",
      "Epoch 57/1000\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.4622 - accuracy: 0.8006\n",
      "Epoch 58/1000\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.4573 - accuracy: 0.8132\n",
      "Epoch 59/1000\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.4529 - accuracy: 0.8090\n",
      "Epoch 60/1000\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4572 - accuracy: 0.7992\n",
      "Epoch 61/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4628 - accuracy: 0.8020\n",
      "Epoch 62/1000\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.4631 - accuracy: 0.8020\n",
      "Epoch 63/1000\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.4630 - accuracy: 0.8090\n",
      "Epoch 64/1000\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.4625 - accuracy: 0.8048\n",
      "Epoch 65/1000\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4603 - accuracy: 0.7992\n",
      "Epoch 66/1000\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4632 - accuracy: 0.8020\n",
      "Epoch 67/1000\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4537 - accuracy: 0.7992\n",
      "Epoch 68/1000\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4591 - accuracy: 0.7949\n",
      "Epoch 69/1000\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4392 - accuracy: 0.8048\n",
      "Epoch 70/1000\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4523 - accuracy: 0.8118\n",
      "Epoch 71/1000\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4507 - accuracy: 0.8160\n",
      "Epoch 72/1000\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4532 - accuracy: 0.8034\n",
      "Epoch 73/1000\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4554 - accuracy: 0.8090\n",
      "Epoch 74/1000\n",
      "712/712 [==============================] - 0s 136us/step - loss: 0.4607 - accuracy: 0.8090\n",
      "Epoch 75/1000\n",
      "712/712 [==============================] - 0s 121us/step - loss: 0.4505 - accuracy: 0.7949\n",
      "Epoch 76/1000\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.4596 - accuracy: 0.7992\n",
      "Epoch 77/1000\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4537 - accuracy: 0.8118\n",
      "Epoch 78/1000\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4576 - accuracy: 0.8048\n",
      "Epoch 79/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 108us/step - loss: 0.4509 - accuracy: 0.8076\n",
      "Epoch 80/1000\n",
      "712/712 [==============================] - 0s 120us/step - loss: 0.4520 - accuracy: 0.8062\n",
      "Epoch 81/1000\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4491 - accuracy: 0.8146\n",
      "Epoch 82/1000\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4445 - accuracy: 0.8118\n",
      "Epoch 83/1000\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4457 - accuracy: 0.8146\n",
      "Epoch 84/1000\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4539 - accuracy: 0.8006\n",
      "Epoch 85/1000\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4591 - accuracy: 0.8104\n",
      "Epoch 86/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4509 - accuracy: 0.8090\n",
      "Epoch 87/1000\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.4418 - accuracy: 0.8174\n",
      "Epoch 88/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4549 - accuracy: 0.8104\n",
      "Epoch 89/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4452 - accuracy: 0.8174\n",
      "Epoch 90/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4466 - accuracy: 0.8146\n",
      "Epoch 91/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4526 - accuracy: 0.8174\n",
      "Epoch 92/1000\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4436 - accuracy: 0.8118\n",
      "Epoch 93/1000\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4636 - accuracy: 0.8104\n",
      "Epoch 94/1000\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4421 - accuracy: 0.8020\n",
      "Epoch 95/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4591 - accuracy: 0.8020\n",
      "Epoch 96/1000\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4423 - accuracy: 0.8174\n",
      "Epoch 97/1000\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4480 - accuracy: 0.8076\n",
      "Epoch 98/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4446 - accuracy: 0.8146\n",
      "Epoch 99/1000\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.4548 - accuracy: 0.8104\n",
      "Epoch 100/1000\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4398 - accuracy: 0.8034\n",
      "Epoch 101/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4476 - accuracy: 0.8160\n",
      "Epoch 102/1000\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4501 - accuracy: 0.8174\n",
      "Epoch 103/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4479 - accuracy: 0.8132\n",
      "Epoch 104/1000\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4495 - accuracy: 0.8076\n",
      "Epoch 105/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4504 - accuracy: 0.7992\n",
      "Epoch 106/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4512 - accuracy: 0.8160\n",
      "Epoch 107/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4476 - accuracy: 0.8076\n",
      "Epoch 108/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4504 - accuracy: 0.8090\n",
      "Epoch 109/1000\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4521 - accuracy: 0.8048\n",
      "Epoch 110/1000\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4464 - accuracy: 0.8146\n",
      "Epoch 111/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4435 - accuracy: 0.8160\n",
      "Epoch 112/1000\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4416 - accuracy: 0.8090\n",
      "Epoch 113/1000\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4476 - accuracy: 0.8104\n",
      "Epoch 114/1000\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4423 - accuracy: 0.8118\n",
      "Epoch 115/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4435 - accuracy: 0.8118\n",
      "Epoch 116/1000\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.4362 - accuracy: 0.81 - 0s 90us/step - loss: 0.4446 - accuracy: 0.8090\n",
      "Epoch 117/1000\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4409 - accuracy: 0.8132\n",
      "Epoch 118/1000\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4383 - accuracy: 0.8230\n",
      "Epoch 119/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4432 - accuracy: 0.8160\n",
      "Epoch 120/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4494 - accuracy: 0.8174\n",
      "Epoch 121/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4398 - accuracy: 0.8118\n",
      "Epoch 122/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4413 - accuracy: 0.8188\n",
      "Epoch 123/1000\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4430 - accuracy: 0.8146\n",
      "Epoch 124/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4464 - accuracy: 0.8090\n",
      "Epoch 125/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4404 - accuracy: 0.8118\n",
      "Epoch 126/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4498 - accuracy: 0.8090\n",
      "Epoch 127/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4518 - accuracy: 0.8160\n",
      "Epoch 128/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4483 - accuracy: 0.8076\n",
      "Epoch 129/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4535 - accuracy: 0.7992\n",
      "Epoch 130/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4423 - accuracy: 0.8132\n",
      "Epoch 131/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4482 - accuracy: 0.8104\n",
      "Epoch 132/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4465 - accuracy: 0.8132\n",
      "Epoch 133/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4410 - accuracy: 0.8132\n",
      "Epoch 134/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4424 - accuracy: 0.8132\n",
      "Epoch 135/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4455 - accuracy: 0.8104\n",
      "Epoch 136/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4407 - accuracy: 0.8104\n",
      "Epoch 137/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4452 - accuracy: 0.8104\n",
      "Epoch 138/1000\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4415 - accuracy: 0.8132\n",
      "Epoch 139/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4405 - accuracy: 0.8090\n",
      "Epoch 140/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4446 - accuracy: 0.8090\n",
      "Epoch 141/1000\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4419 - accuracy: 0.8202\n",
      "Epoch 142/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4427 - accuracy: 0.8174\n",
      "Epoch 143/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4416 - accuracy: 0.8174\n",
      "Epoch 144/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4456 - accuracy: 0.8132\n",
      "Epoch 145/1000\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.4372 - accuracy: 0.8132\n",
      "Epoch 146/1000\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.4414 - accuracy: 0.8174\n",
      "Epoch 147/1000\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.4365 - accuracy: 0.8076\n",
      "Epoch 148/1000\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4331 - accuracy: 0.8104\n",
      "Epoch 149/1000\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4453 - accuracy: 0.8160\n",
      "Epoch 150/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4424 - accuracy: 0.8048\n",
      "Epoch 151/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4410 - accuracy: 0.8146\n",
      "Epoch 152/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4365 - accuracy: 0.8118\n",
      "Epoch 153/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4457 - accuracy: 0.8188\n",
      "Epoch 154/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4393 - accuracy: 0.8146\n",
      "Epoch 155/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4298 - accuracy: 0.8132\n",
      "Epoch 156/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 93us/step - loss: 0.4380 - accuracy: 0.8146\n",
      "Epoch 157/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4389 - accuracy: 0.8034\n",
      "Epoch 158/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4447 - accuracy: 0.8174\n",
      "Epoch 159/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4439 - accuracy: 0.8104\n",
      "Epoch 160/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4388 - accuracy: 0.8104\n",
      "Epoch 161/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4380 - accuracy: 0.8188\n",
      "Epoch 162/1000\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4329 - accuracy: 0.8062\n",
      "Epoch 163/1000\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4431 - accuracy: 0.8104\n",
      "Epoch 164/1000\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4430 - accuracy: 0.8132\n",
      "Epoch 165/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4386 - accuracy: 0.8258\n",
      "Epoch 166/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4456 - accuracy: 0.8104\n",
      "Epoch 167/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4382 - accuracy: 0.8188\n",
      "Epoch 168/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4384 - accuracy: 0.8188\n",
      "Epoch 169/1000\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4405 - accuracy: 0.8174\n",
      "Epoch 170/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4412 - accuracy: 0.8174\n",
      "Epoch 171/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4370 - accuracy: 0.8188\n",
      "Epoch 172/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4376 - accuracy: 0.8174\n",
      "Epoch 173/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4442 - accuracy: 0.8090\n",
      "Epoch 174/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4414 - accuracy: 0.8160 0s - loss: 0.4383 - accuracy: 0.82\n",
      "Epoch 175/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4414 - accuracy: 0.8076\n",
      "Epoch 176/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4455 - accuracy: 0.8160\n",
      "Epoch 177/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4369 - accuracy: 0.8160\n",
      "Epoch 178/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4309 - accuracy: 0.8146\n",
      "Epoch 179/1000\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4341 - accuracy: 0.8188\n",
      "Epoch 180/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4357 - accuracy: 0.8146\n",
      "Epoch 181/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4324 - accuracy: 0.8174\n",
      "Epoch 182/1000\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4447 - accuracy: 0.8160\n",
      "Epoch 183/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4362 - accuracy: 0.8048\n",
      "Epoch 184/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4300 - accuracy: 0.8160\n",
      "Epoch 185/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4442 - accuracy: 0.8118\n",
      "Epoch 186/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4386 - accuracy: 0.8132\n",
      "Epoch 187/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4353 - accuracy: 0.8146\n",
      "Epoch 188/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4374 - accuracy: 0.8062\n",
      "Epoch 189/1000\n",
      "712/712 [==============================] - 0s 105us/step - loss: 0.4374 - accuracy: 0.8188\n",
      "Epoch 190/1000\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4398 - accuracy: 0.8174\n",
      "Epoch 191/1000\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4375 - accuracy: 0.8104\n",
      "Epoch 192/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4447 - accuracy: 0.8118\n",
      "Epoch 193/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4307 - accuracy: 0.8132\n",
      "Epoch 194/1000\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4341 - accuracy: 0.8020\n",
      "Epoch 195/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4388 - accuracy: 0.8132\n",
      "Epoch 196/1000\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4316 - accuracy: 0.8216\n",
      "Epoch 197/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4312 - accuracy: 0.8202\n",
      "Epoch 198/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4374 - accuracy: 0.8202\n",
      "Epoch 199/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4366 - accuracy: 0.8188\n",
      "Epoch 200/1000\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4437 - accuracy: 0.8160\n",
      "Epoch 201/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4352 - accuracy: 0.8188\n",
      "Epoch 202/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4441 - accuracy: 0.8118\n",
      "Epoch 203/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4339 - accuracy: 0.8146\n",
      "Epoch 204/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4288 - accuracy: 0.8230\n",
      "Epoch 205/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4366 - accuracy: 0.8230\n",
      "Epoch 206/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4375 - accuracy: 0.8174\n",
      "Epoch 207/1000\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4302 - accuracy: 0.8230\n",
      "Epoch 208/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4362 - accuracy: 0.8188\n",
      "Epoch 209/1000\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4345 - accuracy: 0.8160\n",
      "Epoch 210/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4365 - accuracy: 0.8160\n",
      "Epoch 211/1000\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4418 - accuracy: 0.8132\n",
      "Epoch 212/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4343 - accuracy: 0.8188\n",
      "Epoch 213/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4370 - accuracy: 0.8160\n",
      "Epoch 214/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4410 - accuracy: 0.8034\n",
      "Epoch 215/1000\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4339 - accuracy: 0.8188\n",
      "Epoch 216/1000\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4343 - accuracy: 0.8076\n",
      "Epoch 217/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4389 - accuracy: 0.8090\n",
      "Epoch 218/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4381 - accuracy: 0.8160\n",
      "Epoch 219/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4290 - accuracy: 0.8272\n",
      "Epoch 220/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4317 - accuracy: 0.8188\n",
      "Epoch 221/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4375 - accuracy: 0.8216\n",
      "Epoch 222/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4335 - accuracy: 0.8160\n",
      "Epoch 223/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4329 - accuracy: 0.8146\n",
      "Epoch 224/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4342 - accuracy: 0.8230\n",
      "Epoch 225/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4284 - accuracy: 0.8174\n",
      "Epoch 226/1000\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4385 - accuracy: 0.8104\n",
      "Epoch 227/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4271 - accuracy: 0.8216\n",
      "Epoch 228/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4352 - accuracy: 0.8202\n",
      "Epoch 229/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4296 - accuracy: 0.8216\n",
      "Epoch 230/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4371 - accuracy: 0.8174\n",
      "Epoch 231/1000\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.4385 - accuracy: 0.8104\n",
      "Epoch 232/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4392 - accuracy: 0.8160\n",
      "Epoch 233/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 94us/step - loss: 0.4410 - accuracy: 0.8104\n",
      "Epoch 234/1000\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4330 - accuracy: 0.8230\n",
      "Epoch 235/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4359 - accuracy: 0.8188\n",
      "Epoch 236/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4335 - accuracy: 0.8118\n",
      "Epoch 237/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4274 - accuracy: 0.8188\n",
      "Epoch 238/1000\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4366 - accuracy: 0.8132\n",
      "Epoch 239/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4360 - accuracy: 0.8174\n",
      "Epoch 240/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4349 - accuracy: 0.8244\n",
      "Epoch 241/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4330 - accuracy: 0.8104\n",
      "Epoch 242/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4285 - accuracy: 0.8216\n",
      "Epoch 243/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4275 - accuracy: 0.8202\n",
      "Epoch 244/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4337 - accuracy: 0.8146\n",
      "Epoch 245/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4338 - accuracy: 0.8174\n",
      "Epoch 246/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4332 - accuracy: 0.8146\n",
      "Epoch 247/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4427 - accuracy: 0.8132\n",
      "Epoch 248/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4308 - accuracy: 0.8301\n",
      "Epoch 249/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4330 - accuracy: 0.8244\n",
      "Epoch 250/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4320 - accuracy: 0.8202\n",
      "Epoch 251/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4363 - accuracy: 0.8132\n",
      "Epoch 252/1000\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.4272 - accuracy: 0.82 - 0s 90us/step - loss: 0.4303 - accuracy: 0.8174\n",
      "Epoch 253/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4272 - accuracy: 0.8160\n",
      "Epoch 254/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4265 - accuracy: 0.8104\n",
      "Epoch 255/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4316 - accuracy: 0.8090\n",
      "Epoch 256/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4349 - accuracy: 0.8244\n",
      "Epoch 257/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4269 - accuracy: 0.8146\n",
      "Epoch 258/1000\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4180 - accuracy: 0.8301\n",
      "Epoch 259/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4314 - accuracy: 0.8174\n",
      "Epoch 260/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4343 - accuracy: 0.8216\n",
      "Epoch 261/1000\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4258 - accuracy: 0.8244\n",
      "Epoch 262/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4237 - accuracy: 0.8216\n",
      "Epoch 263/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4260 - accuracy: 0.8258\n",
      "Epoch 264/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4282 - accuracy: 0.8244\n",
      "Epoch 265/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4236 - accuracy: 0.8287\n",
      "Epoch 266/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4305 - accuracy: 0.8174\n",
      "Epoch 267/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4276 - accuracy: 0.8258\n",
      "Epoch 268/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4296 - accuracy: 0.8244\n",
      "Epoch 269/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4197 - accuracy: 0.8258\n",
      "Epoch 270/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4354 - accuracy: 0.8244\n",
      "Epoch 271/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4291 - accuracy: 0.8329\n",
      "Epoch 272/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4207 - accuracy: 0.8287\n",
      "Epoch 273/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4274 - accuracy: 0.8357\n",
      "Epoch 274/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4182 - accuracy: 0.8272\n",
      "Epoch 275/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4189 - accuracy: 0.8230\n",
      "Epoch 276/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4238 - accuracy: 0.8188\n",
      "Epoch 277/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4319 - accuracy: 0.8174\n",
      "Epoch 278/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4246 - accuracy: 0.8287\n",
      "Epoch 279/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4148 - accuracy: 0.8329\n",
      "Epoch 280/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4275 - accuracy: 0.8272\n",
      "Epoch 281/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4419 - accuracy: 0.8118\n",
      "Epoch 282/1000\n",
      "712/712 [==============================] - 0s 105us/step - loss: 0.4231 - accuracy: 0.8258\n",
      "Epoch 283/1000\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.4194 - accuracy: 0.8244\n",
      "Epoch 284/1000\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4339 - accuracy: 0.8160\n",
      "Epoch 285/1000\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4269 - accuracy: 0.8160\n",
      "Epoch 286/1000\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4298 - accuracy: 0.8258\n",
      "Epoch 287/1000\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4216 - accuracy: 0.8216\n",
      "Epoch 288/1000\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4359 - accuracy: 0.8202\n",
      "Epoch 289/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4244 - accuracy: 0.8301\n",
      "Epoch 290/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4228 - accuracy: 0.8301\n",
      "Epoch 291/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4251 - accuracy: 0.8216\n",
      "Epoch 292/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4343 - accuracy: 0.8244\n",
      "Epoch 293/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4359 - accuracy: 0.8202\n",
      "Epoch 294/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4337 - accuracy: 0.8118\n",
      "Epoch 295/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4221 - accuracy: 0.8230\n",
      "Epoch 296/1000\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4228 - accuracy: 0.8230\n",
      "Epoch 297/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4225 - accuracy: 0.8258\n",
      "Epoch 298/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4285 - accuracy: 0.8174\n",
      "Epoch 299/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4248 - accuracy: 0.8287\n",
      "Epoch 300/1000\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4208 - accuracy: 0.8244\n",
      "Epoch 301/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4104 - accuracy: 0.8272\n",
      "Epoch 302/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4264 - accuracy: 0.8272\n",
      "Epoch 303/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4214 - accuracy: 0.8272\n",
      "Epoch 304/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4200 - accuracy: 0.8230\n",
      "Epoch 305/1000\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4289 - accuracy: 0.8287\n",
      "Epoch 306/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4234 - accuracy: 0.8216\n",
      "Epoch 307/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4170 - accuracy: 0.8272\n",
      "Epoch 308/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4364 - accuracy: 0.8076\n",
      "Epoch 309/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4299 - accuracy: 0.8160\n",
      "Epoch 310/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 94us/step - loss: 0.4304 - accuracy: 0.8090\n",
      "Epoch 311/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4330 - accuracy: 0.8202\n",
      "Epoch 312/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4206 - accuracy: 0.8287\n",
      "Epoch 313/1000\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4268 - accuracy: 0.8188\n",
      "Epoch 314/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4230 - accuracy: 0.8216\n",
      "Epoch 315/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4177 - accuracy: 0.8258\n",
      "Epoch 316/1000\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.4250 - accuracy: 0.8329\n",
      "Epoch 317/1000\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.4246 - accuracy: 0.8272\n",
      "Epoch 318/1000\n",
      "712/712 [==============================] - 0s 141us/step - loss: 0.4213 - accuracy: 0.8258\n",
      "Epoch 319/1000\n",
      "712/712 [==============================] - 0s 126us/step - loss: 0.4268 - accuracy: 0.8230\n",
      "Epoch 320/1000\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.4258 - accuracy: 0.8244\n",
      "Epoch 321/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4233 - accuracy: 0.8202\n",
      "Epoch 322/1000\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4258 - accuracy: 0.8230\n",
      "Epoch 323/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4303 - accuracy: 0.8118\n",
      "Epoch 324/1000\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4194 - accuracy: 0.8188\n",
      "Epoch 325/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4261 - accuracy: 0.8244\n",
      "Epoch 326/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4278 - accuracy: 0.8287\n",
      "Epoch 327/1000\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.4290 - accuracy: 0.8188\n",
      "Epoch 328/1000\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.4272 - accuracy: 0.8174\n",
      "Epoch 329/1000\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.4269 - accuracy: 0.8188\n",
      "Epoch 330/1000\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.4217 - accuracy: 0.8174\n",
      "Epoch 331/1000\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4219 - accuracy: 0.8315\n",
      "Epoch 332/1000\n",
      "712/712 [==============================] - 0s 105us/step - loss: 0.4295 - accuracy: 0.8118\n",
      "Epoch 333/1000\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.4135 - accuracy: 0.8272\n",
      "Epoch 334/1000\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.4194 - accuracy: 0.8371\n",
      "Epoch 335/1000\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.4203 - accuracy: 0.8230\n",
      "Epoch 336/1000\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4243 - accuracy: 0.8244\n",
      "Epoch 337/1000\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4226 - accuracy: 0.8272\n",
      "Epoch 338/1000\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4194 - accuracy: 0.8287\n",
      "Epoch 339/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4340 - accuracy: 0.8188\n",
      "Epoch 340/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4242 - accuracy: 0.8230\n",
      "Epoch 341/1000\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.4188 - accuracy: 0.8329\n",
      "Epoch 342/1000\n",
      "712/712 [==============================] - 0s 142us/step - loss: 0.4184 - accuracy: 0.8301\n",
      "Epoch 343/1000\n",
      "712/712 [==============================] - 0s 173us/step - loss: 0.4205 - accuracy: 0.8146\n",
      "Epoch 344/1000\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.4168 - accuracy: 0.8272\n",
      "Epoch 345/1000\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.4311 - accuracy: 0.8216\n",
      "Epoch 346/1000\n",
      "712/712 [==============================] - 0s 122us/step - loss: 0.4231 - accuracy: 0.8329\n",
      "Epoch 347/1000\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.4213 - accuracy: 0.8272\n",
      "Epoch 348/1000\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.4175 - accuracy: 0.8399\n",
      "Epoch 349/1000\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4239 - accuracy: 0.8202\n",
      "Epoch 350/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4235 - accuracy: 0.8230\n",
      "Epoch 351/1000\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4259 - accuracy: 0.8258\n",
      "Epoch 352/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4284 - accuracy: 0.8174\n",
      "Epoch 353/1000\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4249 - accuracy: 0.8202\n",
      "Epoch 354/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4176 - accuracy: 0.8301\n",
      "Epoch 355/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4220 - accuracy: 0.8329\n",
      "Epoch 356/1000\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4238 - accuracy: 0.8329\n",
      "Epoch 357/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4216 - accuracy: 0.8329\n",
      "Epoch 358/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4146 - accuracy: 0.8371\n",
      "Epoch 359/1000\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4133 - accuracy: 0.8329\n",
      "Epoch 360/1000\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4177 - accuracy: 0.8315\n",
      "Epoch 361/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4130 - accuracy: 0.8329\n",
      "Epoch 362/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4129 - accuracy: 0.8174\n",
      "Epoch 363/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4041 - accuracy: 0.8371\n",
      "Epoch 364/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4245 - accuracy: 0.8287\n",
      "Epoch 365/1000\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4122 - accuracy: 0.8301\n",
      "Epoch 366/1000\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4181 - accuracy: 0.8202\n",
      "Epoch 367/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4245 - accuracy: 0.8272\n",
      "Epoch 368/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4307 - accuracy: 0.8272\n",
      "Epoch 369/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4141 - accuracy: 0.8287\n",
      "Epoch 370/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4131 - accuracy: 0.8357\n",
      "Epoch 371/1000\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4253 - accuracy: 0.8272\n",
      "Epoch 372/1000\n",
      "712/712 [==============================] - 0s 131us/step - loss: 0.4199 - accuracy: 0.8272\n",
      "Epoch 373/1000\n",
      "712/712 [==============================] - 0s 138us/step - loss: 0.4120 - accuracy: 0.8272\n",
      "Epoch 374/1000\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.4179 - accuracy: 0.8315\n",
      "Epoch 375/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4187 - accuracy: 0.8301\n",
      "Epoch 376/1000\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4201 - accuracy: 0.8287\n",
      "Epoch 377/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4201 - accuracy: 0.8160\n",
      "Epoch 378/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4009 - accuracy: 0.8455\n",
      "Epoch 379/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4243 - accuracy: 0.8272\n",
      "Epoch 380/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4200 - accuracy: 0.8287\n",
      "Epoch 381/1000\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4236 - accuracy: 0.8118\n",
      "Epoch 382/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4170 - accuracy: 0.8287\n",
      "Epoch 383/1000\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4151 - accuracy: 0.8329\n",
      "Epoch 384/1000\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4120 - accuracy: 0.8315\n",
      "Epoch 385/1000\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4144 - accuracy: 0.8287\n",
      "Epoch 386/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4197 - accuracy: 0.8315\n",
      "Epoch 387/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 94us/step - loss: 0.4184 - accuracy: 0.8272\n",
      "Epoch 388/1000\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.4246 - accuracy: 0.8258\n",
      "Epoch 389/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4102 - accuracy: 0.8329\n",
      "Epoch 390/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4130 - accuracy: 0.8230\n",
      "Epoch 391/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4240 - accuracy: 0.8104\n",
      "Epoch 392/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4181 - accuracy: 0.8272\n",
      "Epoch 393/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4152 - accuracy: 0.8160\n",
      "Epoch 394/1000\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4205 - accuracy: 0.8258\n",
      "Epoch 395/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4185 - accuracy: 0.8230\n",
      "Epoch 396/1000\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4292 - accuracy: 0.8315\n",
      "Epoch 397/1000\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4242 - accuracy: 0.8174\n",
      "Epoch 398/1000\n",
      "712/712 [==============================] - 0s 148us/step - loss: 0.4110 - accuracy: 0.8258\n",
      "Epoch 399/1000\n",
      "712/712 [==============================] - 0s 128us/step - loss: 0.4059 - accuracy: 0.8371\n",
      "Epoch 400/1000\n",
      "712/712 [==============================] - 0s 125us/step - loss: 0.4167 - accuracy: 0.8287\n",
      "Epoch 401/1000\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.4237 - accuracy: 0.8188\n",
      "Epoch 402/1000\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.4161 - accuracy: 0.8385\n",
      "Epoch 403/1000\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.4190 - accuracy: 0.8329\n",
      "Epoch 404/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4204 - accuracy: 0.8230\n",
      "Epoch 405/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4129 - accuracy: 0.8244\n",
      "Epoch 406/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4130 - accuracy: 0.8287\n",
      "Epoch 407/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4104 - accuracy: 0.8230\n",
      "Epoch 408/1000\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4248 - accuracy: 0.8258\n",
      "Epoch 409/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4151 - accuracy: 0.8287\n",
      "Epoch 410/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4168 - accuracy: 0.8230\n",
      "Epoch 411/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4236 - accuracy: 0.8188\n",
      "Epoch 412/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4305 - accuracy: 0.8188\n",
      "Epoch 413/1000\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4158 - accuracy: 0.8343\n",
      "Epoch 414/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4122 - accuracy: 0.8202\n",
      "Epoch 415/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4180 - accuracy: 0.8301\n",
      "Epoch 416/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4176 - accuracy: 0.8258\n",
      "Epoch 417/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4134 - accuracy: 0.8301\n",
      "Epoch 418/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4050 - accuracy: 0.8315\n",
      "Epoch 419/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4239 - accuracy: 0.8258\n",
      "Epoch 420/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4247 - accuracy: 0.8146\n",
      "Epoch 421/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4089 - accuracy: 0.8357\n",
      "Epoch 422/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4244 - accuracy: 0.8216\n",
      "Epoch 423/1000\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4269 - accuracy: 0.8216\n",
      "Epoch 424/1000\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4116 - accuracy: 0.8272\n",
      "Epoch 425/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4210 - accuracy: 0.8272\n",
      "Epoch 426/1000\n",
      "712/712 [==============================] - 0s 105us/step - loss: 0.4050 - accuracy: 0.8315\n",
      "Epoch 427/1000\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.4214 - accuracy: 0.8216\n",
      "Epoch 428/1000\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4045 - accuracy: 0.8343\n",
      "Epoch 429/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4238 - accuracy: 0.8315\n",
      "Epoch 430/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4160 - accuracy: 0.8343\n",
      "Epoch 431/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4122 - accuracy: 0.8230\n",
      "Epoch 432/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4132 - accuracy: 0.8272\n",
      "Epoch 433/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4133 - accuracy: 0.8343\n",
      "Epoch 434/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4067 - accuracy: 0.8357\n",
      "Epoch 435/1000\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4238 - accuracy: 0.8287\n",
      "Epoch 436/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4227 - accuracy: 0.8244\n",
      "Epoch 437/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4182 - accuracy: 0.8174\n",
      "Epoch 438/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4074 - accuracy: 0.8244\n",
      "Epoch 439/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4152 - accuracy: 0.8258\n",
      "Epoch 440/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4098 - accuracy: 0.8287\n",
      "Epoch 441/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4196 - accuracy: 0.8244\n",
      "Epoch 442/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4152 - accuracy: 0.8385\n",
      "Epoch 443/1000\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4141 - accuracy: 0.8301\n",
      "Epoch 444/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4166 - accuracy: 0.8216\n",
      "Epoch 445/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4257 - accuracy: 0.8188\n",
      "Epoch 446/1000\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.4065 - accuracy: 0.8315\n",
      "Epoch 447/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4201 - accuracy: 0.8174\n",
      "Epoch 448/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4127 - accuracy: 0.8258\n",
      "Epoch 449/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4128 - accuracy: 0.8315\n",
      "Epoch 450/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4100 - accuracy: 0.8258\n",
      "Epoch 451/1000\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4225 - accuracy: 0.8272\n",
      "Epoch 452/1000\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4204 - accuracy: 0.8287\n",
      "Epoch 453/1000\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4131 - accuracy: 0.8216\n",
      "Epoch 454/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4141 - accuracy: 0.8272\n",
      "Epoch 455/1000\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4192 - accuracy: 0.8188\n",
      "Epoch 456/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4099 - accuracy: 0.8399\n",
      "Epoch 457/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4174 - accuracy: 0.8216\n",
      "Epoch 458/1000\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4134 - accuracy: 0.8216\n",
      "Epoch 459/1000\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4166 - accuracy: 0.8329\n",
      "Epoch 460/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4127 - accuracy: 0.8258\n",
      "Epoch 461/1000\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4091 - accuracy: 0.8357\n",
      "Epoch 462/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4053 - accuracy: 0.8329\n",
      "Epoch 463/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4122 - accuracy: 0.8287\n",
      "Epoch 464/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4147 - accuracy: 0.8315\n",
      "Epoch 465/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 87us/step - loss: 0.4109 - accuracy: 0.8301\n",
      "Epoch 466/1000\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.4102 - accuracy: 0.8216\n",
      "Epoch 467/1000\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4203 - accuracy: 0.8287\n",
      "Epoch 468/1000\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4126 - accuracy: 0.8343\n",
      "Epoch 469/1000\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4135 - accuracy: 0.8329\n",
      "Epoch 470/1000\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4085 - accuracy: 0.8272\n",
      "Epoch 471/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4044 - accuracy: 0.8371\n",
      "Epoch 472/1000\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4147 - accuracy: 0.8287\n",
      "Epoch 473/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4142 - accuracy: 0.8287\n",
      "Epoch 474/1000\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4105 - accuracy: 0.8230\n",
      "Epoch 475/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4093 - accuracy: 0.8329\n",
      "Epoch 476/1000\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.4200 - accuracy: 0.8230\n",
      "Epoch 477/1000\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4024 - accuracy: 0.8385\n",
      "Epoch 478/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4065 - accuracy: 0.8357\n",
      "Epoch 479/1000\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4007 - accuracy: 0.8343\n",
      "Epoch 480/1000\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4080 - accuracy: 0.8343\n",
      "Epoch 481/1000\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4132 - accuracy: 0.8216\n",
      "Epoch 482/1000\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4122 - accuracy: 0.8371\n",
      "Epoch 483/1000\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4036 - accuracy: 0.8343\n",
      "Epoch 484/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.3997 - accuracy: 0.8413\n",
      "Epoch 485/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4026 - accuracy: 0.8357\n",
      "Epoch 486/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4160 - accuracy: 0.8329\n",
      "Epoch 487/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4089 - accuracy: 0.8315\n",
      "Epoch 488/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4051 - accuracy: 0.8258\n",
      "Epoch 489/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4183 - accuracy: 0.8174\n",
      "Epoch 490/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4191 - accuracy: 0.8258\n",
      "Epoch 491/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4212 - accuracy: 0.8202\n",
      "Epoch 492/1000\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4119 - accuracy: 0.8329\n",
      "Epoch 493/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4133 - accuracy: 0.8202\n",
      "Epoch 494/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4119 - accuracy: 0.8287\n",
      "Epoch 495/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4063 - accuracy: 0.8315\n",
      "Epoch 496/1000\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4045 - accuracy: 0.8315\n",
      "Epoch 497/1000\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4090 - accuracy: 0.8258\n",
      "Epoch 498/1000\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4181 - accuracy: 0.8244\n",
      "Epoch 499/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4082 - accuracy: 0.8287\n",
      "Epoch 500/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4074 - accuracy: 0.8343\n",
      "Epoch 501/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4104 - accuracy: 0.8371\n",
      "Epoch 502/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4099 - accuracy: 0.8216\n",
      "Epoch 503/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4092 - accuracy: 0.8427\n",
      "Epoch 504/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4096 - accuracy: 0.8343\n",
      "Epoch 505/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4075 - accuracy: 0.8315\n",
      "Epoch 506/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4052 - accuracy: 0.8160\n",
      "Epoch 507/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4112 - accuracy: 0.8272\n",
      "Epoch 508/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4084 - accuracy: 0.8371\n",
      "Epoch 509/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4122 - accuracy: 0.8258\n",
      "Epoch 510/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4069 - accuracy: 0.8343\n",
      "Epoch 511/1000\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4016 - accuracy: 0.8343\n",
      "Epoch 512/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.3967 - accuracy: 0.8371\n",
      "Epoch 513/1000\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.3954 - accuracy: 0.8413\n",
      "Epoch 514/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.3910 - accuracy: 0.8385\n",
      "Epoch 515/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4058 - accuracy: 0.8272\n",
      "Epoch 516/1000\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.4037 - accuracy: 0.8357\n",
      "Epoch 517/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4072 - accuracy: 0.8371\n",
      "Epoch 518/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4252 - accuracy: 0.8216\n",
      "Epoch 519/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4064 - accuracy: 0.8301\n",
      "Epoch 520/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4061 - accuracy: 0.8287\n",
      "Epoch 521/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4094 - accuracy: 0.8315\n",
      "Epoch 522/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4054 - accuracy: 0.8216\n",
      "Epoch 523/1000\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4049 - accuracy: 0.8329\n",
      "Epoch 524/1000\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4047 - accuracy: 0.8343\n",
      "Epoch 525/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4066 - accuracy: 0.8315\n",
      "Epoch 526/1000\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.3973 - accuracy: 0.8385\n",
      "Epoch 527/1000\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4039 - accuracy: 0.8343\n",
      "Epoch 528/1000\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4043 - accuracy: 0.8343\n",
      "Epoch 529/1000\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4072 - accuracy: 0.8315\n",
      "Epoch 530/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.3982 - accuracy: 0.8343\n",
      "Epoch 531/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4096 - accuracy: 0.8315\n",
      "Epoch 532/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4142 - accuracy: 0.8301\n",
      "Epoch 533/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4077 - accuracy: 0.8244\n",
      "Epoch 534/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4022 - accuracy: 0.8301\n",
      "Epoch 535/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4036 - accuracy: 0.8371\n",
      "Epoch 536/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4094 - accuracy: 0.8287\n",
      "Epoch 537/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4079 - accuracy: 0.8244\n",
      "Epoch 538/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4098 - accuracy: 0.8301\n",
      "Epoch 539/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.3985 - accuracy: 0.8385\n",
      "Epoch 540/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4080 - accuracy: 0.8357\n",
      "Epoch 541/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.3972 - accuracy: 0.8413\n",
      "Epoch 542/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4095 - accuracy: 0.8329\n",
      "Epoch 543/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 90us/step - loss: 0.3941 - accuracy: 0.8343\n",
      "Epoch 544/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4086 - accuracy: 0.8301\n",
      "Epoch 545/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4143 - accuracy: 0.8357\n",
      "Epoch 546/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4057 - accuracy: 0.8357\n",
      "Epoch 547/1000\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4018 - accuracy: 0.8371\n",
      "Epoch 548/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.3987 - accuracy: 0.8287\n",
      "Epoch 549/1000\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4038 - accuracy: 0.8272\n",
      "Epoch 550/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.3921 - accuracy: 0.8385\n",
      "Epoch 551/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4012 - accuracy: 0.8315\n",
      "Epoch 552/1000\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.4163 - accuracy: 0.82 - 0s 87us/step - loss: 0.4032 - accuracy: 0.8329\n",
      "Epoch 553/1000\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.3970 - accuracy: 0.8357\n",
      "Epoch 554/1000\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.3901 - accuracy: 0.8399\n",
      "Epoch 555/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.3947 - accuracy: 0.8315\n",
      "Epoch 556/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.3991 - accuracy: 0.8244\n",
      "Epoch 557/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.3929 - accuracy: 0.8385\n",
      "Epoch 558/1000\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4026 - accuracy: 0.8287\n",
      "Epoch 559/1000\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.3977 - accuracy: 0.8455\n",
      "Epoch 560/1000\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4039 - accuracy: 0.8357\n",
      "Epoch 561/1000\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.3901 - accuracy: 0.8216\n",
      "Epoch 562/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.3972 - accuracy: 0.8343\n",
      "Epoch 563/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4001 - accuracy: 0.8287\n",
      "Epoch 564/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.3964 - accuracy: 0.8329\n",
      "Epoch 565/1000\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4017 - accuracy: 0.8371\n",
      "Epoch 566/1000\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4070 - accuracy: 0.8230\n",
      "Epoch 567/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.3972 - accuracy: 0.8343\n",
      "Epoch 568/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.3949 - accuracy: 0.8343\n",
      "Epoch 569/1000\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4079 - accuracy: 0.8301\n",
      "Epoch 570/1000\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4086 - accuracy: 0.8244\n",
      "Epoch 571/1000\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4099 - accuracy: 0.8244\n",
      "Epoch 572/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4041 - accuracy: 0.8343\n",
      "Epoch 573/1000\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4019 - accuracy: 0.8343\n",
      "Epoch 574/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4050 - accuracy: 0.8343\n",
      "Epoch 575/1000\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.3826 - accuracy: 0.83 - 0s 88us/step - loss: 0.3911 - accuracy: 0.8301\n",
      "Epoch 576/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4051 - accuracy: 0.8301\n",
      "Epoch 577/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.3903 - accuracy: 0.8441\n",
      "Epoch 578/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4158 - accuracy: 0.8216\n",
      "Epoch 579/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.3970 - accuracy: 0.8357\n",
      "Epoch 580/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.3933 - accuracy: 0.8343\n",
      "Epoch 581/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4017 - accuracy: 0.8272\n",
      "Epoch 582/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4047 - accuracy: 0.8315\n",
      "Epoch 583/1000\n",
      "712/712 [==============================] - 0s 122us/step - loss: 0.3965 - accuracy: 0.8357\n",
      "Epoch 584/1000\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4127 - accuracy: 0.8343\n",
      "Epoch 585/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4000 - accuracy: 0.8315\n",
      "Epoch 586/1000\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4029 - accuracy: 0.8343\n",
      "Epoch 587/1000\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.3915 - accuracy: 0.8329\n",
      "Epoch 588/1000\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.4258 - accuracy: 0.81 - 0s 87us/step - loss: 0.4087 - accuracy: 0.8244\n",
      "Epoch 589/1000\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4059 - accuracy: 0.8244\n",
      "Epoch 590/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4049 - accuracy: 0.8329\n",
      "Epoch 591/1000\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4034 - accuracy: 0.8272\n",
      "Epoch 592/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.3972 - accuracy: 0.8315\n",
      "Epoch 593/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4010 - accuracy: 0.8258\n",
      "Epoch 594/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4094 - accuracy: 0.8329\n",
      "Epoch 595/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.3987 - accuracy: 0.8272\n",
      "Epoch 596/1000\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.3916 - accuracy: 0.8371\n",
      "Epoch 597/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.3945 - accuracy: 0.8385\n",
      "Epoch 598/1000\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.3955 - accuracy: 0.8371\n",
      "Epoch 599/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.3938 - accuracy: 0.8371\n",
      "Epoch 600/1000\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.3965 - accuracy: 0.8371\n",
      "Epoch 601/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4085 - accuracy: 0.8216\n",
      "Epoch 602/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4025 - accuracy: 0.8315\n",
      "Epoch 603/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4039 - accuracy: 0.8118\n",
      "Epoch 604/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.3988 - accuracy: 0.8244\n",
      "Epoch 605/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4105 - accuracy: 0.8230\n",
      "Epoch 606/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.3967 - accuracy: 0.8272\n",
      "Epoch 607/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.3978 - accuracy: 0.8315\n",
      "Epoch 608/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4032 - accuracy: 0.8329\n",
      "Epoch 609/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.3935 - accuracy: 0.8301\n",
      "Epoch 610/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4014 - accuracy: 0.8287\n",
      "Epoch 611/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4027 - accuracy: 0.8385\n",
      "Epoch 612/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4055 - accuracy: 0.8230\n",
      "Epoch 613/1000\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.3892 - accuracy: 0.8441\n",
      "Epoch 614/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4015 - accuracy: 0.8244\n",
      "Epoch 615/1000\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.4058 - accuracy: 0.8258\n",
      "Epoch 616/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4020 - accuracy: 0.8329\n",
      "Epoch 617/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4051 - accuracy: 0.8244\n",
      "Epoch 618/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4004 - accuracy: 0.8329\n",
      "Epoch 619/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4007 - accuracy: 0.8244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 620/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4021 - accuracy: 0.8230\n",
      "Epoch 621/1000\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.3951 - accuracy: 0.8371\n",
      "Epoch 622/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4043 - accuracy: 0.8188\n",
      "Epoch 623/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4067 - accuracy: 0.8258\n",
      "Epoch 624/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.3993 - accuracy: 0.8258\n",
      "Epoch 625/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4000 - accuracy: 0.8329\n",
      "Epoch 626/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4013 - accuracy: 0.8188\n",
      "Epoch 627/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4014 - accuracy: 0.8287\n",
      "Epoch 628/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.3965 - accuracy: 0.8343\n",
      "Epoch 629/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.3996 - accuracy: 0.8301\n",
      "Epoch 630/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.3905 - accuracy: 0.8230\n",
      "Epoch 631/1000\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.3945 - accuracy: 0.8371\n",
      "Epoch 632/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4050 - accuracy: 0.8244\n",
      "Epoch 633/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4126 - accuracy: 0.8160\n",
      "Epoch 634/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.3988 - accuracy: 0.8202\n",
      "Epoch 635/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.3924 - accuracy: 0.8272\n",
      "Epoch 636/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4011 - accuracy: 0.8174\n",
      "Epoch 637/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.3964 - accuracy: 0.8287\n",
      "Epoch 638/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.3971 - accuracy: 0.8272\n",
      "Epoch 639/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.3960 - accuracy: 0.8272\n",
      "Epoch 640/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4050 - accuracy: 0.8244\n",
      "Epoch 641/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4020 - accuracy: 0.8315\n",
      "Epoch 642/1000\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.4003 - accuracy: 0.8216\n",
      "Epoch 643/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4035 - accuracy: 0.8272\n",
      "Epoch 644/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.3993 - accuracy: 0.8301\n",
      "Epoch 645/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.3939 - accuracy: 0.8329\n",
      "Epoch 646/1000\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.4053 - accuracy: 0.8258\n",
      "Epoch 647/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4030 - accuracy: 0.8132\n",
      "Epoch 648/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.3954 - accuracy: 0.8357\n",
      "Epoch 649/1000\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4036 - accuracy: 0.8230\n",
      "Epoch 650/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.3952 - accuracy: 0.8301\n",
      "Epoch 651/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4025 - accuracy: 0.8413\n",
      "Epoch 652/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.3956 - accuracy: 0.8315\n",
      "Epoch 653/1000\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.3987 - accuracy: 0.8287\n",
      "Epoch 654/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4077 - accuracy: 0.8216\n",
      "Epoch 655/1000\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.3887 - accuracy: 0.8413\n",
      "Epoch 656/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4071 - accuracy: 0.8160\n",
      "Epoch 657/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4058 - accuracy: 0.8216\n",
      "Epoch 658/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.3912 - accuracy: 0.8343\n",
      "Epoch 659/1000\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.3939 - accuracy: 0.8287\n",
      "Epoch 660/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.3967 - accuracy: 0.8287\n",
      "Epoch 661/1000\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.3981 - accuracy: 0.8272\n",
      "Epoch 662/1000\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4080 - accuracy: 0.8272\n",
      "Epoch 663/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.3945 - accuracy: 0.8315\n",
      "Epoch 664/1000\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.3986 - accuracy: 0.8202\n",
      "Epoch 665/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.3974 - accuracy: 0.8272\n",
      "Epoch 666/1000\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.3927 - accuracy: 0.8301\n",
      "Epoch 667/1000\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.3927 - accuracy: 0.8329\n",
      "Epoch 668/1000\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.3931 - accuracy: 0.8315\n",
      "Epoch 669/1000\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.3990 - accuracy: 0.8258\n",
      "Epoch 670/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.3999 - accuracy: 0.8244\n",
      "Epoch 671/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.3948 - accuracy: 0.8301\n",
      "Epoch 672/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4017 - accuracy: 0.8258\n",
      "Epoch 673/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.3948 - accuracy: 0.8329\n",
      "Epoch 674/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4054 - accuracy: 0.8230\n",
      "Epoch 675/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.3964 - accuracy: 0.8244\n",
      "Epoch 676/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.3935 - accuracy: 0.8244\n",
      "Epoch 677/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.3959 - accuracy: 0.8244\n",
      "Epoch 678/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.3894 - accuracy: 0.8315\n",
      "Epoch 679/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.3968 - accuracy: 0.8216\n",
      "Epoch 680/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.3960 - accuracy: 0.8272\n",
      "Epoch 681/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.3894 - accuracy: 0.8357\n",
      "Epoch 682/1000\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.3963 - accuracy: 0.8188\n",
      "Epoch 683/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4094 - accuracy: 0.8132\n",
      "Epoch 684/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.3966 - accuracy: 0.8315\n",
      "Epoch 685/1000\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.3891 - accuracy: 0.8272\n",
      "Epoch 686/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.3958 - accuracy: 0.8357\n",
      "Epoch 687/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.3994 - accuracy: 0.8230\n",
      "Epoch 688/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.3883 - accuracy: 0.8301\n",
      "Epoch 689/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.3913 - accuracy: 0.8301\n",
      "Epoch 690/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4018 - accuracy: 0.8216\n",
      "Epoch 691/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.3947 - accuracy: 0.8258\n",
      "Epoch 692/1000\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.3926 - accuracy: 0.8118\n",
      "Epoch 693/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.3930 - accuracy: 0.8301\n",
      "Epoch 694/1000\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.3995 - accuracy: 0.8272\n",
      "Epoch 695/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.3982 - accuracy: 0.8188\n",
      "Epoch 696/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.3939 - accuracy: 0.8287\n",
      "Epoch 697/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4012 - accuracy: 0.8258\n",
      "Epoch 698/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 97us/step - loss: 0.3956 - accuracy: 0.8385\n",
      "Epoch 699/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.3968 - accuracy: 0.8287\n",
      "Epoch 700/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.3999 - accuracy: 0.8216\n",
      "Epoch 701/1000\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.3988 - accuracy: 0.8315\n",
      "Epoch 702/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.3941 - accuracy: 0.8258\n",
      "Epoch 703/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.3956 - accuracy: 0.8301\n",
      "Epoch 704/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.3978 - accuracy: 0.8357\n",
      "Epoch 705/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.3974 - accuracy: 0.8287\n",
      "Epoch 706/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4000 - accuracy: 0.8202\n",
      "Epoch 707/1000\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.3943 - accuracy: 0.82 - 0s 90us/step - loss: 0.3964 - accuracy: 0.8272\n",
      "Epoch 708/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4005 - accuracy: 0.8272\n",
      "Epoch 709/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.3949 - accuracy: 0.8301\n",
      "Epoch 710/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.3818 - accuracy: 0.8371\n",
      "Epoch 711/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.3968 - accuracy: 0.8315\n",
      "Epoch 712/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.3901 - accuracy: 0.8329\n",
      "Epoch 713/1000\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4000 - accuracy: 0.8216\n",
      "Epoch 714/1000\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.3850 - accuracy: 0.8329\n",
      "Epoch 715/1000\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.3917 - accuracy: 0.8258\n",
      "Epoch 716/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.3924 - accuracy: 0.8287\n",
      "Epoch 717/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.3961 - accuracy: 0.8287\n",
      "Epoch 718/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.3940 - accuracy: 0.8371\n",
      "Epoch 719/1000\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4044 - accuracy: 0.8244\n",
      "Epoch 720/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.3895 - accuracy: 0.8329\n",
      "Epoch 721/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.3974 - accuracy: 0.8287\n",
      "Epoch 722/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4013 - accuracy: 0.8343\n",
      "Epoch 723/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.3940 - accuracy: 0.8272\n",
      "Epoch 724/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4019 - accuracy: 0.8188\n",
      "Epoch 725/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.3888 - accuracy: 0.8329\n",
      "Epoch 726/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.3935 - accuracy: 0.8413\n",
      "Epoch 727/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.3983 - accuracy: 0.8244\n",
      "Epoch 728/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.3903 - accuracy: 0.8329\n",
      "Epoch 729/1000\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.3905 - accuracy: 0.8244\n",
      "Epoch 730/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.3811 - accuracy: 0.8413\n",
      "Epoch 731/1000\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.3831 - accuracy: 0.8343\n",
      "Epoch 732/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.3895 - accuracy: 0.8399\n",
      "Epoch 733/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.3862 - accuracy: 0.8427\n",
      "Epoch 734/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.3940 - accuracy: 0.8357\n",
      "Epoch 735/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.3885 - accuracy: 0.8357\n",
      "Epoch 736/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.3994 - accuracy: 0.8216\n",
      "Epoch 737/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.3884 - accuracy: 0.8427\n",
      "Epoch 738/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.3898 - accuracy: 0.8413\n",
      "Epoch 739/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.3924 - accuracy: 0.8371\n",
      "Epoch 740/1000\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4025 - accuracy: 0.8272\n",
      "Epoch 741/1000\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.3903 - accuracy: 0.8385\n",
      "Epoch 742/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.3995 - accuracy: 0.8258\n",
      "Epoch 743/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.3927 - accuracy: 0.8272\n",
      "Epoch 744/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.3950 - accuracy: 0.8301\n",
      "Epoch 745/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.3947 - accuracy: 0.8385\n",
      "Epoch 746/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.3963 - accuracy: 0.8371\n",
      "Epoch 747/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.3828 - accuracy: 0.8413\n",
      "Epoch 748/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.3968 - accuracy: 0.8230\n",
      "Epoch 749/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.3926 - accuracy: 0.8272\n",
      "Epoch 750/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.3940 - accuracy: 0.8343\n",
      "Epoch 751/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.3911 - accuracy: 0.8343\n",
      "Epoch 752/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.3914 - accuracy: 0.8329\n",
      "Epoch 753/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.3936 - accuracy: 0.8329\n",
      "Epoch 754/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.3937 - accuracy: 0.8357\n",
      "Epoch 755/1000\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.3986 - accuracy: 0.8272\n",
      "Epoch 756/1000\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.3920 - accuracy: 0.8329\n",
      "Epoch 757/1000\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.3886 - accuracy: 0.8287\n",
      "Epoch 758/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.3911 - accuracy: 0.8343\n",
      "Epoch 759/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.3982 - accuracy: 0.8216\n",
      "Epoch 760/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.3918 - accuracy: 0.8301\n",
      "Epoch 761/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.3877 - accuracy: 0.8315\n",
      "Epoch 762/1000\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.3893 - accuracy: 0.8258\n",
      "Epoch 763/1000\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.3870 - accuracy: 0.8385\n",
      "Epoch 764/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.3899 - accuracy: 0.8357\n",
      "Epoch 765/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4050 - accuracy: 0.8272\n",
      "Epoch 766/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.3967 - accuracy: 0.8371\n",
      "Epoch 767/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.3923 - accuracy: 0.8315\n",
      "Epoch 768/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.3875 - accuracy: 0.8202\n",
      "Epoch 769/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.3909 - accuracy: 0.8385\n",
      "Epoch 770/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.3842 - accuracy: 0.8315\n",
      "Epoch 771/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.3951 - accuracy: 0.8329\n",
      "Epoch 772/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.3939 - accuracy: 0.8216\n",
      "Epoch 773/1000\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4000 - accuracy: 0.8258\n",
      "Epoch 774/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.3993 - accuracy: 0.8329\n",
      "Epoch 775/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 93us/step - loss: 0.3897 - accuracy: 0.8216\n",
      "Epoch 776/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.3931 - accuracy: 0.8315\n",
      "Epoch 777/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.3950 - accuracy: 0.8301\n",
      "Epoch 778/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.3895 - accuracy: 0.8413\n",
      "Epoch 779/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.3985 - accuracy: 0.8329\n",
      "Epoch 780/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.3919 - accuracy: 0.8441\n",
      "Epoch 781/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.3967 - accuracy: 0.8301\n",
      "Epoch 782/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.3940 - accuracy: 0.8202\n",
      "Epoch 783/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4090 - accuracy: 0.8301\n",
      "Epoch 784/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4017 - accuracy: 0.8301\n",
      "Epoch 785/1000\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.3869 - accuracy: 0.8244\n",
      "Epoch 786/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.3868 - accuracy: 0.8244\n",
      "Epoch 787/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.3923 - accuracy: 0.8371\n",
      "Epoch 788/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.3867 - accuracy: 0.8343\n",
      "Epoch 789/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.3858 - accuracy: 0.8329\n",
      "Epoch 790/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.3846 - accuracy: 0.8343\n",
      "Epoch 791/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.3975 - accuracy: 0.8244\n",
      "Epoch 792/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.3817 - accuracy: 0.8399\n",
      "Epoch 793/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.3870 - accuracy: 0.8258\n",
      "Epoch 794/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.3868 - accuracy: 0.8371\n",
      "Epoch 795/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.3892 - accuracy: 0.8287\n",
      "Epoch 796/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.3889 - accuracy: 0.8272\n",
      "Epoch 797/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.3976 - accuracy: 0.8287\n",
      "Epoch 798/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.3885 - accuracy: 0.8371\n",
      "Epoch 799/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.3981 - accuracy: 0.8258\n",
      "Epoch 800/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.3913 - accuracy: 0.8301\n",
      "Epoch 801/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4009 - accuracy: 0.8287\n",
      "Epoch 802/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.3872 - accuracy: 0.8230\n",
      "Epoch 803/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.3923 - accuracy: 0.8301\n",
      "Epoch 804/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.3959 - accuracy: 0.8371\n",
      "Epoch 805/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.3881 - accuracy: 0.8287\n",
      "Epoch 806/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.3901 - accuracy: 0.8287\n",
      "Epoch 807/1000\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.3881 - accuracy: 0.8385\n",
      "Epoch 808/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.3911 - accuracy: 0.8427\n",
      "Epoch 809/1000\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.3922 - accuracy: 0.8343\n",
      "Epoch 810/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.3894 - accuracy: 0.8329\n",
      "Epoch 811/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.3984 - accuracy: 0.8301\n",
      "Epoch 812/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.3918 - accuracy: 0.8301\n",
      "Epoch 813/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.3915 - accuracy: 0.8258\n",
      "Epoch 814/1000\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.3907 - accuracy: 0.8343\n",
      "Epoch 815/1000\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4030 - accuracy: 0.8258\n",
      "Epoch 816/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4017 - accuracy: 0.8188\n",
      "Epoch 817/1000\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.3724 - accuracy: 0.8483\n",
      "Epoch 818/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.3972 - accuracy: 0.8202\n",
      "Epoch 819/1000\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.3961 - accuracy: 0.8287\n",
      "Epoch 820/1000\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.3914 - accuracy: 0.8287\n",
      "Epoch 821/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.3894 - accuracy: 0.8287\n",
      "Epoch 822/1000\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.3897 - accuracy: 0.8188\n",
      "Epoch 823/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.3888 - accuracy: 0.8385\n",
      "Epoch 824/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.3869 - accuracy: 0.8413\n",
      "Epoch 825/1000\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.3877 - accuracy: 0.8357\n",
      "Epoch 826/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.3965 - accuracy: 0.8244\n",
      "Epoch 827/1000\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.3879 - accuracy: 0.8287\n",
      "Epoch 828/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.3917 - accuracy: 0.8230\n",
      "Epoch 829/1000\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.3937 - accuracy: 0.8230\n",
      "Epoch 830/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.3897 - accuracy: 0.8371\n",
      "Epoch 831/1000\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.3840 - accuracy: 0.8343\n",
      "Epoch 832/1000\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.3995 - accuracy: 0.8315\n",
      "Epoch 833/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.3900 - accuracy: 0.8230\n",
      "Epoch 834/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.3913 - accuracy: 0.8287\n",
      "Epoch 835/1000\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.3910 - accuracy: 0.8343\n",
      "Epoch 836/1000\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.3981 - accuracy: 0.8258\n",
      "Epoch 837/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.3981 - accuracy: 0.8329\n",
      "Epoch 838/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.3907 - accuracy: 0.8371\n",
      "Epoch 839/1000\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.3976 - accuracy: 0.8315\n",
      "Epoch 840/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.3951 - accuracy: 0.8301\n",
      "Epoch 841/1000\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.3877 - accuracy: 0.8287\n",
      "Epoch 842/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.3877 - accuracy: 0.8315\n",
      "Epoch 843/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.3922 - accuracy: 0.8357\n",
      "Epoch 844/1000\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.3902 - accuracy: 0.8329\n",
      "Epoch 845/1000\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.3803 - accuracy: 0.8371\n",
      "Epoch 846/1000\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.3897 - accuracy: 0.8413\n",
      "Epoch 847/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.3845 - accuracy: 0.8413\n",
      "Epoch 848/1000\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.3885 - accuracy: 0.8385\n",
      "Epoch 849/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.3867 - accuracy: 0.8357\n",
      "Epoch 850/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.3948 - accuracy: 0.8413\n",
      "Epoch 851/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.3924 - accuracy: 0.8244\n",
      "Epoch 852/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.3935 - accuracy: 0.8315\n",
      "Epoch 853/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 97us/step - loss: 0.3832 - accuracy: 0.8371\n",
      "Epoch 854/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.3964 - accuracy: 0.8357\n",
      "Epoch 855/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.3897 - accuracy: 0.8329\n",
      "Epoch 856/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.3892 - accuracy: 0.8469\n",
      "Epoch 857/1000\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.3978 - accuracy: 0.8371\n",
      "Epoch 858/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.3978 - accuracy: 0.8301\n",
      "Epoch 859/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.3983 - accuracy: 0.8272\n",
      "Epoch 860/1000\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.3912 - accuracy: 0.8469\n",
      "Epoch 861/1000\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.3858 - accuracy: 0.8343\n",
      "Epoch 862/1000\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.3933 - accuracy: 0.8343\n",
      "Epoch 863/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.3835 - accuracy: 0.8371\n",
      "Epoch 864/1000\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.3846 - accuracy: 0.8385\n",
      "Epoch 865/1000\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.3953 - accuracy: 0.8329\n",
      "Epoch 866/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.3915 - accuracy: 0.8371\n",
      "Epoch 867/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.3781 - accuracy: 0.8455\n",
      "Epoch 868/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.3889 - accuracy: 0.8441\n",
      "Epoch 869/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4039 - accuracy: 0.8202\n",
      "Epoch 870/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.3876 - accuracy: 0.8483\n",
      "Epoch 871/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.3846 - accuracy: 0.8455\n",
      "Epoch 872/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.3892 - accuracy: 0.8413\n",
      "Epoch 873/1000\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.3917 - accuracy: 0.8413\n",
      "Epoch 874/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4012 - accuracy: 0.8343\n",
      "Epoch 875/1000\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.3841 - accuracy: 0.8315\n",
      "Epoch 876/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.3848 - accuracy: 0.8413\n",
      "Epoch 877/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.3911 - accuracy: 0.8371\n",
      "Epoch 878/1000\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.3856 - accuracy: 0.8329\n",
      "Epoch 879/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.3854 - accuracy: 0.8371\n",
      "Epoch 880/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.3883 - accuracy: 0.8329\n",
      "Epoch 881/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.3843 - accuracy: 0.8455\n",
      "Epoch 882/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.3986 - accuracy: 0.8413\n",
      "Epoch 883/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.3863 - accuracy: 0.8413\n",
      "Epoch 884/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.3945 - accuracy: 0.8258\n",
      "Epoch 885/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.3903 - accuracy: 0.8343\n",
      "Epoch 886/1000\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.3910 - accuracy: 0.8329\n",
      "Epoch 887/1000\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.3935 - accuracy: 0.8427\n",
      "Epoch 888/1000\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.3787 - accuracy: 0.8483\n",
      "Epoch 889/1000\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.3880 - accuracy: 0.8385\n",
      "Epoch 890/1000\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.3878 - accuracy: 0.8315\n",
      "Epoch 891/1000\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.3828 - accuracy: 0.8357\n",
      "Epoch 892/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.3922 - accuracy: 0.8301\n",
      "Epoch 893/1000\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.3947 - accuracy: 0.8301\n",
      "Epoch 894/1000\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.3874 - accuracy: 0.8329\n",
      "Epoch 895/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.3765 - accuracy: 0.8357\n",
      "Epoch 896/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4012 - accuracy: 0.8188\n",
      "Epoch 897/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.3860 - accuracy: 0.8483\n",
      "Epoch 898/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.3889 - accuracy: 0.8441\n",
      "Epoch 899/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.3859 - accuracy: 0.8399\n",
      "Epoch 900/1000\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.3954 - accuracy: 0.8202\n",
      "Epoch 901/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.3806 - accuracy: 0.8483\n",
      "Epoch 902/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.3791 - accuracy: 0.8329\n",
      "Epoch 903/1000\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.3884 - accuracy: 0.8427\n",
      "Epoch 904/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.3847 - accuracy: 0.8413\n",
      "Epoch 905/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4057 - accuracy: 0.8315\n",
      "Epoch 906/1000\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.3924 - accuracy: 0.8287\n",
      "Epoch 907/1000\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.3916 - accuracy: 0.8329\n",
      "Epoch 908/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.3945 - accuracy: 0.8329\n",
      "Epoch 909/1000\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.3824 - accuracy: 0.8315\n",
      "Epoch 910/1000\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.3834 - accuracy: 0.8399\n",
      "Epoch 911/1000\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.3851 - accuracy: 0.8272\n",
      "Epoch 912/1000\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.3882 - accuracy: 0.8287\n",
      "Epoch 913/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4055 - accuracy: 0.8315\n",
      "Epoch 914/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.3890 - accuracy: 0.8329\n",
      "Epoch 915/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.3946 - accuracy: 0.8301\n",
      "Epoch 916/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.3751 - accuracy: 0.8511\n",
      "Epoch 917/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4002 - accuracy: 0.8258\n",
      "Epoch 918/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.3978 - accuracy: 0.8258\n",
      "Epoch 919/1000\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.3945 - accuracy: 0.8315\n",
      "Epoch 920/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.3881 - accuracy: 0.8413\n",
      "Epoch 921/1000\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.3806 - accuracy: 0.8497\n",
      "Epoch 922/1000\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.3953 - accuracy: 0.8371\n",
      "Epoch 923/1000\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.3790 - accuracy: 0.8315\n",
      "Epoch 924/1000\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.3849 - accuracy: 0.8413\n",
      "Epoch 925/1000\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.3879 - accuracy: 0.8329\n",
      "Epoch 926/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4035 - accuracy: 0.8174\n",
      "Epoch 927/1000\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.3910 - accuracy: 0.8202\n",
      "Epoch 928/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.3916 - accuracy: 0.8399\n",
      "Epoch 929/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.3817 - accuracy: 0.8343\n",
      "Epoch 930/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.3816 - accuracy: 0.8469\n",
      "Epoch 931/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 97us/step - loss: 0.3847 - accuracy: 0.8441\n",
      "Epoch 932/1000\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.3805 - accuracy: 0.8441\n",
      "Epoch 933/1000\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.3850 - accuracy: 0.8357\n",
      "Epoch 934/1000\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4011 - accuracy: 0.8301\n",
      "Epoch 935/1000\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.3946 - accuracy: 0.8357\n",
      "Epoch 936/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.3923 - accuracy: 0.8301\n",
      "Epoch 937/1000\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.3921 - accuracy: 0.8301\n",
      "Epoch 938/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.3923 - accuracy: 0.8329\n",
      "Epoch 939/1000\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.3926 - accuracy: 0.8399\n",
      "Epoch 940/1000\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.3937 - accuracy: 0.8357\n",
      "Epoch 941/1000\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4065 - accuracy: 0.8272\n",
      "Epoch 942/1000\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.3882 - accuracy: 0.8357\n",
      "Epoch 943/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4019 - accuracy: 0.8244\n",
      "Epoch 944/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.3928 - accuracy: 0.8385\n",
      "Epoch 945/1000\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.3805 - accuracy: 0.8427\n",
      "Epoch 946/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.3889 - accuracy: 0.8287\n",
      "Epoch 947/1000\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.3877 - accuracy: 0.8385\n",
      "Epoch 948/1000\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.3922 - accuracy: 0.8329\n",
      "Epoch 949/1000\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.4034 - accuracy: 0.8230\n",
      "Epoch 950/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.3961 - accuracy: 0.8329\n",
      "Epoch 951/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.3782 - accuracy: 0.8329\n",
      "Epoch 952/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.3865 - accuracy: 0.8315\n",
      "Epoch 953/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.3929 - accuracy: 0.8272\n",
      "Epoch 954/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.3731 - accuracy: 0.8483\n",
      "Epoch 955/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.3906 - accuracy: 0.8329\n",
      "Epoch 956/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4052 - accuracy: 0.8188\n",
      "Epoch 957/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.3855 - accuracy: 0.8399\n",
      "Epoch 958/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.3877 - accuracy: 0.8385\n",
      "Epoch 959/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.3840 - accuracy: 0.8315\n",
      "Epoch 960/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.3867 - accuracy: 0.8385\n",
      "Epoch 961/1000\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.3876 - accuracy: 0.8441\n",
      "Epoch 962/1000\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.3843 - accuracy: 0.84 - 0s 94us/step - loss: 0.3917 - accuracy: 0.8343\n",
      "Epoch 963/1000\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.3982 - accuracy: 0.8244\n",
      "Epoch 964/1000\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.3881 - accuracy: 0.8357\n",
      "Epoch 965/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.3872 - accuracy: 0.8455\n",
      "Epoch 966/1000\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.3887 - accuracy: 0.8427 0s - loss: 0.3955 - accuracy: 0.84\n",
      "Epoch 967/1000\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.3884 - accuracy: 0.8371\n",
      "Epoch 968/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.3881 - accuracy: 0.8371\n",
      "Epoch 969/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.3918 - accuracy: 0.8287\n",
      "Epoch 970/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.3800 - accuracy: 0.8357\n",
      "Epoch 971/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4010 - accuracy: 0.8329\n",
      "Epoch 972/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.3887 - accuracy: 0.8371\n",
      "Epoch 973/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.3818 - accuracy: 0.8371\n",
      "Epoch 974/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.3866 - accuracy: 0.8385\n",
      "Epoch 975/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.3836 - accuracy: 0.8385\n",
      "Epoch 976/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.3980 - accuracy: 0.8315\n",
      "Epoch 977/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.3879 - accuracy: 0.8399\n",
      "Epoch 978/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.3867 - accuracy: 0.8413\n",
      "Epoch 979/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.3937 - accuracy: 0.8287\n",
      "Epoch 980/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.3950 - accuracy: 0.8258\n",
      "Epoch 981/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.3826 - accuracy: 0.8343\n",
      "Epoch 982/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.3854 - accuracy: 0.8413\n",
      "Epoch 983/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.3883 - accuracy: 0.8357\n",
      "Epoch 984/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.3855 - accuracy: 0.8441\n",
      "Epoch 985/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.3935 - accuracy: 0.8343\n",
      "Epoch 986/1000\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.3892 - accuracy: 0.8315\n",
      "Epoch 987/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.3824 - accuracy: 0.8343\n",
      "Epoch 988/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.3762 - accuracy: 0.8469\n",
      "Epoch 989/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.3905 - accuracy: 0.8385\n",
      "Epoch 990/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.3908 - accuracy: 0.8301\n",
      "Epoch 991/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.3916 - accuracy: 0.8287\n",
      "Epoch 992/1000\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.3879 - accuracy: 0.8287\n",
      "Epoch 993/1000\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.3870 - accuracy: 0.8315\n",
      "Epoch 994/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.3866 - accuracy: 0.8216\n",
      "Epoch 995/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.3868 - accuracy: 0.8371\n",
      "Epoch 996/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.3832 - accuracy: 0.8399\n",
      "Epoch 997/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.3930 - accuracy: 0.8244\n",
      "Epoch 998/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.3913 - accuracy: 0.8357\n",
      "Epoch 999/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.3815 - accuracy: 0.8385\n",
      "Epoch 1000/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.3886 - accuracy: 0.8244\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1acc7d6c3c8>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train,Y_train,batch_size = 10, epochs = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "# #Gridsearch\n",
    "# from keras.wrappers.scikit_learn import KerasClassifier\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# classifier = KerasClassifier(build_fn = build_neural_net)\n",
    "# parameters = {'batch_size' : [15,25,32],\n",
    "#               'epochs' : [1000,1500],\n",
    "#               'optimizer' : ['adam','rmsprop'],\n",
    "#              'initializer':['uniform','glorot_uniform'],\n",
    "#              'layer_1_activation':['relu','selu','sigmoid'],\n",
    "#               'layer_2_activation':['relu','selu','sigmoid']}\n",
    "# gridSeach = GridSearchCV(estimator = classifier, param_grid = parameters, scoring = 'accuracy', cv = 3)\n",
    "# #gridSeach = gridSeach.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>fare_col_scaled_col</th>\n",
       "      <th>age_col_scaled_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.030937</td>\n",
       "      <td>0.402845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024106</td>\n",
       "      <td>0.735874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.221098</td>\n",
       "      <td>0.345427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015127</td>\n",
       "      <td>0.409966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>0.529167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.718648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>0.333943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.028302</td>\n",
       "      <td>0.621037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.071731</td>\n",
       "      <td>0.299492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.162932</td>\n",
       "      <td>0.598069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>712 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  SibSp  Parch Cabin  Sex_female  Sex_male  Embarked_C  Embarked_Q  \\\n",
       "403       3      1      0     0           0         1           0           0   \n",
       "626       2      0      0     0           0         1           0           1   \n",
       "393       1      1      0     1           1         0           1           0   \n",
       "428       3      0      0     0           0         1           0           1   \n",
       "400       3      0      0     0           0         1           0           0   \n",
       "..      ...    ...    ...   ...         ...       ...         ...         ...   \n",
       "152       3      0      0     0           0         1           0           0   \n",
       "376       3      0      0     0           1         0           0           0   \n",
       "132       3      1      0     0           1         0           0           0   \n",
       "145       2      1      1     0           0         1           0           0   \n",
       "62        1      1      0     1           0         1           0           0   \n",
       "\n",
       "     Embarked_S  fare_col_scaled_col  age_col_scaled_col  \n",
       "403           1             0.030937            0.402845  \n",
       "626           0             0.024106            0.735874  \n",
       "393           0             0.221098            0.345427  \n",
       "428           0             0.015127            0.409966  \n",
       "400           1             0.015469            0.529167  \n",
       "..          ...                  ...                 ...  \n",
       "152           1             0.015713            0.718648  \n",
       "376           1             0.014151            0.333943  \n",
       "132           1             0.028302            0.621037  \n",
       "145           1             0.071731            0.299492  \n",
       "62            1             0.162932            0.598069  \n",
       "\n",
       "[712 rows x 11 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_ann = classifier.predict(X_test)\n",
    "Y_pred_ann   = [1  if rows>0.6 else 0 for rows in Y_pred_ann]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8491620111731844"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_test,Y_pred_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_svm = svm.SVC(C=2.8,kernel='rbf',cache_size=500,break_ties=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amakkad\\AppData\\Local\\Continuum\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "fit_svm_model = model_svm.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm = fit_svm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8603351955307262"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_test,y_pred_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amakkad\\AppData\\Local\\Continuum\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\amakkad\\AppData\\Local\\Continuum\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# create ensemble\n",
    "\n",
    "# random forest = model3\n",
    "# ann = classifier\n",
    "# svm = fit_svm_model\n",
    "# let's try Logistic regression as well\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# model_ensemble_lasso_1 = Lasso(alpha=0.1)\n",
    "# model_fit_lasso_ensemble_1 = model_ensemble_lasso_1.fit(X_train,Y_train)\n",
    "# _lasso_1 = model_fit_lasso_ensemble_1.predict(X_test)\n",
    "# model_ensemble_lasso_2 = Lasso(alpha=0.01)\n",
    "# model_fit_lasso_ensemble_2 = model_ensemble_lasso_2.fit(X_train,Y_train)\n",
    "# _lasso_2 = model_fit_lasso_ensemble_2.predict(X_test)\n",
    "lg = LogisticRegression(penalty='none',random_state=12)\n",
    "fit_lg = lg.fit(X_train,Y_train)\n",
    "_lg1 = fit_lg.predict(X_test)\n",
    "lg2 = LogisticRegression(random_state=12)\n",
    "fit_lg2 = lg2.fit(X_train,Y_train)\n",
    "_lg2 = fit_lg2.predict(X_test)\n",
    "_ann = classifier.predict(X_test)\n",
    "_ann = [1  if rows>0.6 else 0 for rows in _ann]\n",
    "_random_forest = model3.predict(X_test)\n",
    "_svm = fit_svm_model.predict(X_test)\n",
    "ensemble_array = (_lg1+_lg2+np.array(_ann)*3+np.array(_random_forest)*2+np.array(_svm)*3)\n",
    "ensemble_array = [1  if rows>5 else 0 for rows in ensemble_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8603351955307262"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_test,ensemble_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>fare_col_scaled_col</th>\n",
       "      <th>age_col_scaled_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.030937</td>\n",
       "      <td>0.402845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024106</td>\n",
       "      <td>0.735874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.221098</td>\n",
       "      <td>0.345427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015127</td>\n",
       "      <td>0.409966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>0.529167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.718648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>0.333943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.028302</td>\n",
       "      <td>0.621037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.071731</td>\n",
       "      <td>0.299492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.162932</td>\n",
       "      <td>0.598069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>712 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  SibSp  Parch Cabin  Sex_female  Sex_male  Embarked_C  Embarked_Q  \\\n",
       "403       3      1      0     0           0         1           0           0   \n",
       "626       2      0      0     0           0         1           0           1   \n",
       "393       1      1      0     1           1         0           1           0   \n",
       "428       3      0      0     0           0         1           0           1   \n",
       "400       3      0      0     0           0         1           0           0   \n",
       "..      ...    ...    ...   ...         ...       ...         ...         ...   \n",
       "152       3      0      0     0           0         1           0           0   \n",
       "376       3      0      0     0           1         0           0           0   \n",
       "132       3      1      0     0           1         0           0           0   \n",
       "145       2      1      1     0           0         1           0           0   \n",
       "62        1      1      0     1           0         1           0           0   \n",
       "\n",
       "     Embarked_S  fare_col_scaled_col  age_col_scaled_col  \n",
       "403           1             0.030937            0.402845  \n",
       "626           0             0.024106            0.735874  \n",
       "393           0             0.221098            0.345427  \n",
       "428           0             0.015127            0.409966  \n",
       "400           1             0.015469            0.529167  \n",
       "..          ...                  ...                 ...  \n",
       "152           1             0.015713            0.718648  \n",
       "376           1             0.014151            0.333943  \n",
       "132           1             0.028302            0.621037  \n",
       "145           1             0.071731            0.299492  \n",
       "62            1             0.162932            0.598069  \n",
       "\n",
       "[712 rows x 11 columns]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_copy = X_train.copy(deep=True)\n",
    "X_train_copy['Cabin'] = X_train_copy['Cabin'].astype(str).astype(int)\n",
    "X_test_copy = X_test.copy(deep=True)\n",
    "X_test_copy['Cabin'] = X_test_copy['Cabin'].astype(str).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "train = xgb.DMatrix(X_train_copy, label=Y_train)\n",
    "test = xgb.DMatrix(X_test_copy, label=Y_test)\n",
    "param = {\n",
    "    'max_depth': 4,\n",
    "    'eta': 0.3,\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': 3} \n",
    "epochs = 10 \n",
    "model_xg = xgb.train(param, train, epochs)\n",
    "#predictions = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "        1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "        1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1,\n",
       "        0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "        0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1,\n",
       "        0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1,\n",
       "        0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "        1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1,\n",
       "        0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1,\n",
       "        0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "        0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1,\n",
       "        1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "        0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
       "        0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0,\n",
       "        1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "        0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "        1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1,\n",
       "        0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n",
       "        1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "        1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "        1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1,\n",
       "        1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        0, 1, 1, 0, 1, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeEnsemble(X_test):\n",
    "    _lg1 = fit_lg.predict(X_test)\n",
    "    _lg2 = fit_lg2.predict(X_test)\n",
    "    _ann = classifier.predict(X_test)\n",
    "    _ann = [1  if rows>0.6 else 0 for rows in _ann]\n",
    "    _random_forest = model3.predict(X_test)\n",
    "    _svm = fit_svm_model.predict(X_test)\n",
    "    ensemble_array = (_lg1+_lg2+np.array(_ann)*3+np.array(_random_forest)*2+np.array(_svm)*3)\n",
    "    ensemble_array = [1  if rows>3 else 0 for rows in ensemble_array]\n",
    "    return ensemble_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('../titanic/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()\n",
    "test_data_original = test_data.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performing same data transformations\n",
    "from sklearn import preprocessing\n",
    "#test_data.drop(columns=['PassengerId'],inplace=True)\n",
    "test_data['Cabin'] = test_data['Cabin'].fillna(0)\n",
    "test_data['Cabin'] = test_data['Cabin'].where(test_data['Cabin']==0,1)\n",
    "test_data.drop(columns=['Name','Ticket'],inplace=True)\n",
    "test_data = pd.concat([test_data,pd.get_dummies(test_data['Sex'],prefix='Sex')],axis = 1)\n",
    "test_data.drop(columns='Sex',inplace=True)\n",
    "test_data = pd.concat([test_data,pd.get_dummies(test_data['Embarked'],prefix='Embarked')],axis = 1)\n",
    "test_data.drop(columns=['Embarked'],inplace=True)\n",
    "test_data['Fare'] = test_data['Fare'].fillna(test_data['Fare'].median())\n",
    "fare_col = test_data.Fare.values\n",
    "fare_col = fare_col.reshape(-1, 1)\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "fare_col_scaled = min_max_scaler.fit_transform(fare_col)\n",
    "test_data['fare_col_scaled_col'] = fare_col_scaled\n",
    "test_data.drop(columns=['Fare'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_df_test = test_data[test_data['Age'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_nan_df_test = test_data[test_data['Age'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>fare_col_scaled_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [PassengerId, Pclass, Age, SibSp, Parch, Cabin, Sex_female, Sex_male, Embarked_C, Embarked_Q, Embarked_S, fare_col_scaled_col]\n",
       "Index: []"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_nan_df_test[non_nan_df_test.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>fare_col_scaled_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>902</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>914</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.061842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>921</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.042315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>925</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.045771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>928</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PassengerId  Pclass  Age  SibSp  Parch Cabin  Sex_female  Sex_male  \\\n",
       "10          902       3  NaN      0      0     0           0         1   \n",
       "22          914       1  NaN      0      0     0           1         0   \n",
       "29          921       3  NaN      2      0     0           0         1   \n",
       "33          925       3  NaN      1      2     0           1         0   \n",
       "36          928       3  NaN      0      0     0           1         0   \n",
       "\n",
       "    Embarked_C  Embarked_Q  Embarked_S  fare_col_scaled_col  \n",
       "10           0           0           1             0.015412  \n",
       "22           0           0           1             0.061842  \n",
       "29           1           0           0             0.042315  \n",
       "33           0           0           1             0.045771  \n",
       "36           0           0           1             0.015713  "
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.predict(x_test_laso)\n",
    "y_col = [col for col in nan_df_test.columns if col!='Age']\n",
    "y_col = [col for col in y_col if col!='PassengerId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86, 10)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_df_test[y_col].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "ages_test = model.predict(nan_df_test[y_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ages_test = classifier.predict(nan_df_test[y_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amakkad\\AppData\\Local\\Continuum\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "nan_df_test['age_predicted'] = ages_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>fare_col_scaled_col</th>\n",
       "      <th>age_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>902</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015412</td>\n",
       "      <td>28.529624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>914</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.061842</td>\n",
       "      <td>38.618131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>921</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.042315</td>\n",
       "      <td>18.873590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>925</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.045771</td>\n",
       "      <td>20.031961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>928</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>25.741804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PassengerId  Pclass  Age  SibSp  Parch Cabin  Sex_female  Sex_male  \\\n",
       "10          902       3  NaN      0      0     0           0         1   \n",
       "22          914       1  NaN      0      0     0           1         0   \n",
       "29          921       3  NaN      2      0     0           0         1   \n",
       "33          925       3  NaN      1      2     0           1         0   \n",
       "36          928       3  NaN      0      0     0           1         0   \n",
       "\n",
       "    Embarked_C  Embarked_Q  Embarked_S  fare_col_scaled_col  age_predicted  \n",
       "10           0           0           1             0.015412      28.529624  \n",
       "22           0           0           1             0.061842      38.618131  \n",
       "29           1           0           0             0.042315      18.873590  \n",
       "33           0           0           1             0.045771      20.031961  \n",
       "36           0           0           1             0.015713      25.741804  "
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amakkad\\AppData\\Local\\Continuum\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\pandas\\core\\frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "nan_df_test.drop(columns=['Age'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amakkad\\AppData\\Local\\Continuum\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "nan_df_test['Age'] = ages_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>fare_col_scaled_col</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>902</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015412</td>\n",
       "      <td>28.529624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>914</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.061842</td>\n",
       "      <td>38.618131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>921</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.042315</td>\n",
       "      <td>18.873590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>925</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.045771</td>\n",
       "      <td>20.031961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>928</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>25.741804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PassengerId  Pclass  SibSp  Parch Cabin  Sex_female  Sex_male  Embarked_C  \\\n",
       "10          902       3      0      0     0           0         1           0   \n",
       "22          914       1      0      0     0           1         0           0   \n",
       "29          921       3      2      0     0           0         1           1   \n",
       "33          925       3      1      2     0           1         0           0   \n",
       "36          928       3      0      0     0           1         0           0   \n",
       "\n",
       "    Embarked_Q  Embarked_S  fare_col_scaled_col        Age  \n",
       "10           0           1             0.015412  28.529624  \n",
       "22           0           1             0.061842  38.618131  \n",
       "29           0           0             0.042315  18.873590  \n",
       "33           0           1             0.045771  20.031961  \n",
       "36           0           1             0.015713  25.741804  "
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_df_test.drop(columns=['age_predicted'],inplace=True)\n",
    "nan_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>fare_col_scaled_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.013663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.018909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.023984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass   Age  SibSp  Parch Cabin  Sex_female  Sex_male  \\\n",
       "0          892       3  34.5      0      0     0           0         1   \n",
       "1          893       3  47.0      1      0     0           1         0   \n",
       "2          894       2  62.0      0      0     0           0         1   \n",
       "3          895       3  27.0      0      0     0           0         1   \n",
       "4          896       3  22.0      1      1     0           1         0   \n",
       "\n",
       "   Embarked_C  Embarked_Q  Embarked_S  fare_col_scaled_col  \n",
       "0           0           1           0             0.015282  \n",
       "1           0           0           1             0.013663  \n",
       "2           0           1           0             0.018909  \n",
       "3           0           0           1             0.016908  \n",
       "4           0           0           1             0.023984  "
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_nan_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_data = pd.concat([non_nan_df_test,nan_df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>fare_col_scaled_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.013663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.018909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.023984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass   Age  SibSp  Parch Cabin  Sex_female  Sex_male  \\\n",
       "0          892       3  34.5      0      0     0           0         1   \n",
       "1          893       3  47.0      1      0     0           1         0   \n",
       "2          894       2  62.0      0      0     0           0         1   \n",
       "3          895       3  27.0      0      0     0           0         1   \n",
       "4          896       3  22.0      1      1     0           1         0   \n",
       "\n",
       "   Embarked_C  Embarked_Q  Embarked_S  fare_col_scaled_col  \n",
       "0           0           1           0             0.015282  \n",
       "1           0           0           1             0.013663  \n",
       "2           0           1           0             0.018909  \n",
       "3           0           0           1             0.016908  \n",
       "4           0           0           1             0.023984  "
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_col = final_test_data.Age.values\n",
    "age_col = age_col.reshape(-1, 1)\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "age_col_scaled = min_max_scaler.fit_transform(age_col)\n",
    "final_test_data['age_col_scaled_col'] = age_col_scaled\n",
    "final_test_data.drop(columns=['Age'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>fare_col_scaled_col</th>\n",
       "      <th>age_col_scaled_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015282</td>\n",
       "      <td>0.500479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.013663</td>\n",
       "      <td>0.650937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.018909</td>\n",
       "      <td>0.831487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016908</td>\n",
       "      <td>0.410204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.023984</td>\n",
       "      <td>0.350021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass  SibSp  Parch Cabin  Sex_female  Sex_male  Embarked_C  \\\n",
       "0          892       3      0      0     0           0         1           0   \n",
       "1          893       3      1      0     0           1         0           0   \n",
       "2          894       2      0      0     0           0         1           0   \n",
       "3          895       3      0      0     0           0         1           0   \n",
       "4          896       3      1      1     0           1         0           0   \n",
       "\n",
       "   Embarked_Q  Embarked_S  fare_col_scaled_col  age_col_scaled_col  \n",
       "0           1           0             0.015282            0.500479  \n",
       "1           0           1             0.013663            0.650937  \n",
       "2           1           0             0.018909            0.831487  \n",
       "3           0           1             0.016908            0.410204  \n",
       "4           0           1             0.023984            0.350021  "
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_col_final_test = [col for col in final_test_data.columns if col!='PassengerId']\n",
    "#x_col_final_test = [items for items in x_col_final_test if items!='SibSp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>fare_col_scaled_col</th>\n",
       "      <th>age_col_scaled_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [PassengerId, Pclass, SibSp, Parch, Cabin, Sex_female, Sex_male, Embarked_C, Embarked_Q, Embarked_S, fare_col_scaled_col, age_col_scaled_col]\n",
       "Index: []"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_test_data[final_test_data.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_res = classifier.predict(final_test_data[x_col_final_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_res   = [1  if rows>0.80 else 0 for rows in final_res]\n",
    "final_res = makeEnsemble(final_test_data[x_col_final_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_data['Survived'] = final_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>fare_col_scaled_col</th>\n",
       "      <th>age_col_scaled_col</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015282</td>\n",
       "      <td>0.500479</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.013663</td>\n",
       "      <td>0.650937</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.018909</td>\n",
       "      <td>0.831487</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016908</td>\n",
       "      <td>0.410204</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.023984</td>\n",
       "      <td>0.350021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass  SibSp  Parch Cabin  Sex_female  Sex_male  Embarked_C  \\\n",
       "0          892       3      0      0     0           0         1           0   \n",
       "1          893       3      1      0     0           1         0           0   \n",
       "2          894       2      0      0     0           0         1           0   \n",
       "3          895       3      0      0     0           0         1           0   \n",
       "4          896       3      1      1     0           1         0           0   \n",
       "\n",
       "   Embarked_Q  Embarked_S  fare_col_scaled_col  age_col_scaled_col  Survived  \n",
       "0           1           0             0.015282            0.500479         0  \n",
       "1           0           1             0.013663            0.650937         0  \n",
       "2           1           0             0.018909            0.831487         0  \n",
       "3           0           1             0.016908            0.410204         0  \n",
       "4           0           1             0.023984            0.350021         1  "
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_test_data[['PassengerId','Survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('results_titanic_5.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
